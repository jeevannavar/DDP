---
title: "DNA Methylation"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

Importing all the requisite packages first.
```{r}
library(tidyverse)
library(data.table)
library(readr)
library(broom)
library(caret)
library(parallel)
library(foreach)
```

# Importing data

```{r}
#The file has a second row that is unnecessary. So we will load the first row first and then load the rest of it.
cnames <- read_delim("/data/users/bs16b001/firehose/stddata__2016_01_28/BRCA/20160128/gdac.broadinstitute.org_BRCA.Merge_methylation__humanmethylation450__jhu_usc_edu__Level_3__within_bioassay_data_set_function__data.Level_3.2016012800.0.0/meth.txt", 
      "\t", escape_double = FALSE, trim_ws = TRUE, n_max=1, col_names = FALSE)

#Here, we import the complete methylation data with the correct column names and making sure that the beta values are imported as numeric types rather than character type.
meth <- read_delim("/data/users/bs16b001/firehose/stddata__2016_01_28/BRCA/20160128/gdac.broadinstitute.org_BRCA.Merge_methylation__humanmethylation450__jhu_usc_edu__Level_3__within_bioassay_data_set_function__data.Level_3.2016012800.0.0/meth.txt", 
    "\t", escape_double = FALSE, na = "NA", col_names = unlist(c(cnames[1,])),
    trim_ws = TRUE, skip = 2)
```

#Basic Processing

Some basic processing of the imported file
```{r}
meth <- meth[complete.cases(meth), ] %>%
      rename(Gene_symbol = "TCGA-3C-AAAU-01A-11D-A41Q-05_1") %>%
      select(!ends_with("_1") & !ends_with("_2") & !ends_with("_3")) %>%
      select(!starts_with("Hybrid")) %>%
      group_by(Gene_symbol) %>%
      summarize(across(everything(), list(mean))) %>%
      column_to_rownames("Gene_symbol")
      
meth <- meth[is.finite(rowSums(meth)),]
```

Now to make the rows into columns and vice verse, basically transposing the table. This way we will have the sample ids as the row names and each of the methylation features as individual columns.
```{r}
#Custom function to transpose while preserving names
transpose_df <- function(df) {
  t_df <- data.table::transpose(df)
  colnames(t_df) <- rownames(df)
  rownames(t_df) <- colnames(df)
  t_df <- t_df %>%
    tibble::rownames_to_column(.data = .) %>%
    tibble::as_tibble(.)
  return(t_df)
}

meth <- transpose_df(meth)
```

Now we will format the sample id names and then select only those samples for which we have labels.
```{r}
pattern <- "^(\\w{4}\\-\\w{2}\\-\\w{4}\\-\\w{2}).*"
meth <- meth %>%  
  mutate(rowname =sub(pattern, "\\1", rowname)) %>%
  rename(Sample_ID = rowname)
```

In order to get the samples that we can use, we will need to import the PAM50_subtype file and get the ids from there.
```{r}
pam50 <- read_csv("PAM50_subtype.csv")
meth <- meth[match(pam50$patient_id, meth$Sample_ID),]
```

### Writing to file

Here we are writing the complete data to a parseable file. This might be considered a kind of checkpoint too. We can later load this file to continue pre-processing.
```{r}
meth %>%
  rename(patient_id = "Sample_ID") %>%
  write.csv("meth_complete.csv", row.names = FALSE)
```


# Further processing
```{r}
#If you are using this script right from the top, then you could comment out the next line
meth <- read_csv("meth_complete.csv")
pam50 <- read_csv("PAM50_subtype.csv")

# Getting the training indices
trte <- file("trte_partition.txt", open = "r")
lines <- readLines(trte)
close(trte)
train_idx <- unlist(strsplit(lines[2], ","))

# Selecting only training samples for doing the processing
meth_train <- filter(meth, meth$patient_id %in% train_idx)
pam50_train <- filter(pam50, pam50$patient_id %in% train_idx)

#Check that the labels are identical
identical(pam50_train$patient_id, meth_train$patient_id) #This has to be true
```

## ANOVA
```{r}
num_cpus <- 40
cl <- makeCluster(num_cpus)
doParallel::registerDoParallel(cl)
anova_summary <- foreach(i = 3:ncol(meth_train)) %dopar% {
  column <- names(meth_train[i]) 
  avz <- broom:: tidy(aov(meth_train[,i][[1]] ~ unlist(pam50_train$cancer_subtype))) # Each ANOVA test iterating through each column
  return(c(gene=column, f_value=avz$statistic[[1]], p_value=avz$p.value[[1]]))
}
stopCluster(cl)
anova_summary <- as.data.frame(do.call(rbind, anova_summary), stringsAsFactors = FALSE)
anova_summary <- transform(anova_summary, p_value = as.numeric(p_value), f_value = as.numeric(f_value))
```

Filter the features according to the ANOVA p-value and then sort them according to the f_values, which is not necessary here, but can be useful for functional and representational purposes later
```{r}
meth_sorted <- anova_summary %>% 
                  filter(p_value<=0.001/nrow(anova_summary)) %>% 
                  arrange(desc(f_value))
```
Now to select the columns in the dataframe and then export them to csv.
```{r}
namelist <- c(meth_sorted["gene"])
index <- match(namelist[[1]], names(meth))
index <- prepend(index,1)     #To add the column with the patient_ids too to the output
meth_anova <- meth[,index]  

#write.csv(meth_anova, "meth_anova.csv", row.names = FALSE)
```
Now to try a better approach to get the best features: A greedy approach to selecting the top non-correlated features
```{r}
greedySelect <- function(dframe, featureList, corrThreshold = 0.8, max_features = 1000){
  selected = c(featureList[1])
    for (i in c(2:length(featureList))) {
      tempList <- c(cor(dframe[featureList[i]], dframe[selected[1]])) 
      for (s in c(1:length(selected))){
        temp <- cor(dframe[featureList[i]], dframe[selected[s]])
        tempList <- append(tempList, temp)
        if (abs(temp) > corrThreshold) {break}
        }
      if (all( abs(tempList) < corrThreshold)) {
        selected <- append(selected, featureList[i])
      }
      if (length(selected) == max_features) {break}
    }
  return(selected)
  }
```

```{r}
meth_best1000 <- greedySelect(meth_anova, meth_sorted["gene"][[1]], corrThreshold = 0.7)

index <- match(meth_best1000, names(meth_anova))
index <- prepend(index,1)     #To add the column with the patient_ids too to the output
meth_top1000 <- meth_anova[,index]
write.csv(meth_top1000, "meth_top1000.csv", row.names = FALSE)
```

## Elastic Net
As a precursor for the next code block, run the first code block under the heading of further processing.
```{r}
#Remember to scale and center the values
a <- seq(0.1, 0.9, 0.05)    #Alpha values search grid

X <- scale(as.matrix(meth_train[,2:ncol(meth_train)]), center = TRUE, scale = TRUE)
Y <- as.factor(as.matrix(pam50_train$cancer_subtype))

num_cpus <- 25
cl <- makeCluster(num_cpus) 
doParallel::registerDoParallel(cl)
search <- foreach(i = a, .combine = rbind) %dopar% {
  cv <- glmnet::cv.glmnet(X, Y, family = "multinomial", nfold = 10, type.measure = "deviance", parallel = TRUE, alpha = i)
  data.frame(cvm = cv$cvm[cv$lambda == cv$lambda.1se], lambda.1se = cv$lambda.1se, alpha = i)
}
stopCluster(cl)
cv <- search[search$cvm == min(search$cvm), ]
model <- glmnet(X, Y, family = "multinomial", lambda = cv$lambda.1se, alpha = cv$alpha)

coeff = coef(model)
out <- 0
#Coeff is a list because of multinomial classification
for (i in 1:length(coeff)) {
  temp <- coeff[i][[1]]
  var <- names(temp[which(temp !=0),])
  out <- c(out,var)
}

selectedVar <- unique(out)[3:length(unique(out))]
```
```{r}
index <- match(selectedVar, names(meth))
index <- prepend(index,1)     #To add the column with the patient_ids too to the output
meth_elasticnet <- meth[,index]
write.csv(meth_elasticnet, "meth_elasticnet.csv", row.names = FALSE)
```

