---
title: "Data Processing"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table)
library(broom)
library(caret)
library(foreach)
library(parallel)
library(doParallel)
library(glmnet)
```

This markdown document illustrates the following processing steps:
* Pre-processing
* Ranking of features using ANOVA
* Selection of the most informative features using a greedy method
* Scaling and normalization
* Creation of pairwise interaction features
* Ranking and selection of the pairwise interaction features
* Scaling and normalization of the interaction features

# Custom functions

```{r}
# Custom function to transpose while preserving names
transpose_df <- function(df) {
  t_df <- data.table::transpose(df)
  colnames(t_df) <- rownames(df)
  rownames(t_df) <- colnames(df)
  t_df <- t_df %>%
    tibble::rownames_to_column(.data = .) %>%
    tibble::as_tibble(.)
  return(t_df)
}

# To perform ANOVA
run_anova <- function(train_data, train_labels, num_cpus=40) {
  num_cpus <- 40
  cl <- makeCluster(num_cpus)
  doParallel::registerDoParallel(cl)
  anova_summary <- foreach(i = 2:ncol(train_data)) %dopar% {
    column <- names(train_data[i]) 
    avz <- broom:: tidy(aov(train_data[,i][[1]] ~ unlist(train_labels$cancer_subtype))) # Each ANOVA test iterating through each column
    return(c(gene=column, f_value=avz$statistic[[1]], p_value=avz$p.value[[1]]))
  }
  stopCluster(cl)
  anova_summary <- as.data.frame(do.call(rbind, anova_summary), stringsAsFactors = FALSE)
  anova_summary <- transform(anova_summary, p_value = as.numeric(p_value), f_value = as.numeric(f_value))
  return(anova_summary)
}

# A greedy approach to selecting the top non-correlated features
greedySelect <- function(dframe, featureList, corrThreshold = 0.8, max_features = 1000){
  selected = c(featureList[1])
    for (i in c(2:length(featureList))) {
      tempList <- c(cor(dframe[featureList[i]], dframe[selected[1]])) 
      for (s in c(1:length(selected))){
        temp <- cor(dframe[featureList[i]], dframe[selected[s]])
        tempList <- append(tempList, temp)
        if (abs(temp) > corrThreshold) {break}
        }
      if (all( abs(tempList) < corrThreshold)) {
        selected <- append(selected, featureList[i])
      }
      if (length(selected) == max_features) {break}
    }
  return(selected)
}
```


# Loading data

```{r message=FALSE, warning=FALSE}
cerebellum <- read_delim("../../../HBTRC_data/GN326_MeanDataAnnotated_rev081815.txt", 
                         "\t", escape_double = FALSE, trim_ws = TRUE, skip = 32)
visualCortex <- read_delim("../../../HBTRC_data/GN327_MeanDataAnnotated_rev081815.txt",
                           "\t", escape_double = FALSE, trim_ws = TRUE, skip = 32)
prefrontalCortex <- read_delim("../../../HBTRC_data/GN328_MeanDataAnnotated_rev081815.txt",
                               "\t", escape_double = FALSE, trim_ws = TRUE, skip = 32)
labels <- read_csv("disease_class.csv")

# Getting the training indices
trte <- file("trte_partition.txt", open = "r")
lines <- readLines(trte)
close(trte)
train_idx <- unlist(strsplit(lines[2], ","))
```

# Pre-processing

## Cerebellum
```{r}
cerebellum <- cerebellum %>%
  dplyr::select("Gene Symbol" | "Gene Id" | starts_with("HB")) %>%
  dplyr::rename(Gene_Symbol = "Gene Symbol", GeneID = "Gene Id") %>%
  filter(GeneID != "None") %>%
  mutate(Gene = paste(Gene_Symbol, GeneID, sep = "|")) %>%
  dplyr::select(!GeneID & !Gene_Symbol) %>%
  group_by(Gene) %>%
  summarize(across(everything(), list(mean))) %>%
  remove_rownames() %>%
  column_to_rownames("Gene")

# Keep only finite features
cerebellum <- cerebellum[is.finite(rowSums(cerebellum)),]

# Transposing to get sample ids as row names and genes as column names
cerebellum <- transpose_df(cerebellum)

# 
pattern <- "^(\\w{2}\\_\\w{3}\\_\\w{1,2})\\_1$"
cerebellum <- cerebellum %>%  
  mutate(rowname = sub(pattern, "\\1", rowname)) %>%
  dplyr::rename(Sample_ID = rowname)

cerebellum <- cerebellum[match(labels$patient_id, cerebellum$Sample_ID),]
```

## Pre-frontal Cortex
```{r}

```

## Primary Visual Cortex
```{r}

```


# Ranking of fearures using ANOVA

## Cerebellum
```{r}
# Selecting only training samples for doing the processing
cerebellum_train <- filter(cerebellum, cerebellum$patient_id %in% train_idx)
labels_train <- filter(labels, labels$patient_id %in% train_idx)

#Check that the labels are identical
identical(cerebellum_train$patient_id, labels_train$patient_id) 


```

## Pre-frontal Cortex
```{r}

```

## Primary Visual Cortex
```{r}

```


# Selection of the most informative features using a greedy method

## Cerebellum
```{r}

```

## Pre-frontal Cortex
```{r}

```

## Primary Visual Cortex
```{r}

```

# Scaling and Normalization (and saving to files)

## Cerebellum
```{r}

```

## Pre-frontal Cortex
```{r}

```

## Primary Visual Cortex
```{r}

```


# Pariwise interaction features 

For each of the pairs, the data is generated, top features selected, the data normalized, and then saved to files.

## Inter-tissue interaction

### Cerebellum X Prefrontal Cortex

### Prefrontal Cortex X Primary Visual Cortex

### Primary Visual Cortex X Cerebellum

## Intra-tissue interaction

## Cerebellum X Cerebellum

## Prefrontal Cortex X Prefrontal Cortex

## Primary Visual Cortex X Primary Visual Cortex

