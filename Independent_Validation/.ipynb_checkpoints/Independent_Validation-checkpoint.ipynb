{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will perform independent validation of my Graph Convolution Network based model. \n",
    "\n",
    "I validate my model and consequently the biomarkers I produce using the model on the TCGA BRCA multi-omics data set using the following three methods:\n",
    "1. Generate biomarkers from both the data sets (TCGA BRCA & METABRIC) separately and then compare them\n",
    "2. Train the model on TCGA BRCA data and then validate on METABRIC data\n",
    "3. Train and test on METABRIC data but with only features selected from the TCGA BRCA data\n",
    "4. Train the model on TCGA BRCA data, impute the other omics data for METABRIC data using TCGA BRCA, and then validate on the the imputed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Biomarker comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will generate biomarkers using our model and LIME on both the data sets and then compare the biomarker sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary libraries and functions\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from main import train_model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting all variables for run\n",
    "# SEED can be \"random\" or integer, if integer, it will be used as the seed for random, numpy, torch, and cuda\n",
    "SEED = 42 \n",
    "\n",
    "# change label from text to integer\n",
    "label_dict = {'Normal':0, 'Basal':1, 'Her2':2, 'LumA':3, 'LumB':4}\n",
    "\n",
    "COMBINER = False \n",
    "doSMOTE = True \n",
    "\n",
    "# Training parameters\n",
    "num_epoch = 850\n",
    "test_interval = 50\n",
    "lr = 5e-4\n",
    "weight_decay = 1e-3\n",
    "dropout = 0.25\n",
    "adj_parameter = 8 # average number of edge per node in adj matrix\n",
    "\n",
    "VERBOSE = 1 #0, only print final result; 1, only testing result; 2, training and testing result\n",
    "OUTPUT_FILES = False #Boolean to determine whether to output loss and metrics as csv files\n",
    "MAKE_PLOTS = False #Boolean to determine whether to output loss and metrics as plots in png format\n",
    "REPEATS = 1 #Integer, how many times to independently train the model\n",
    "feature_extract = [\"lime\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCGA BRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TITLE = \"TCGA BRCA mRNA Expression\"\n",
    "RUN_TITLE_SHORT = \"tcga_brca_mrna\"\n",
    "\n",
    "# pre-processed data\n",
    "mrna = \"../R/TCGA BRCA/mrna_top1000.csv\"\n",
    "meta_csv = \"../R/TCGA BRCA/PAM50_subtype.csv\"\n",
    "trte_partition_file = \"../R/TCGA BRCA/trte_partition.txt\"\n",
    "\n",
    "load_list = [mrna, meta_csv, trte_partition_file]\n",
    "GCN_names = [\"mRNA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-19 21:04:45.596722 \n",
      "\n",
      "TCGA BRCA mRNA Expression\n",
      "SEED =  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n",
      "\n",
      "Test: Epoch 0\n",
      "Train Accuracy: 0.1770   Test ACC: 0.4837\n",
      "Train F1: 0.1286         Test F1: 0.3154\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.0191              0.1359              0.0000\n",
      "Basal \t           0.2000              0.4306              0.1522              0.0000\n",
      "Her2 \t           0.2000              0.0957              0.0543              0.0000\n",
      "LumA \t           0.2000              0.0000              0.4837              1.0000\n",
      "LumB \t           0.2000              0.3397              0.1739              0.0000\n",
      "\n",
      "\n",
      "Test: Epoch 50\n",
      "Train Accuracy: 0.6153   Test ACC: 0.4457\n",
      "Train F1: 0.6063         Test F1: 0.3306\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.8469              0.1359              0.9200\n",
      "Basal \t           0.2000              0.7512              0.1522              0.8929\n",
      "Her2 \t           0.2000              0.6746              0.0543              1.0000\n",
      "LumA \t           0.2000              0.3301              0.4837              0.0000\n",
      "LumB \t           0.2000              0.4737              0.1739              0.7500\n",
      "\n",
      "\n",
      "Test: Epoch 100\n",
      "Train Accuracy: 0.8201   Test ACC: 0.4457\n",
      "Train F1: 0.8170         Test F1: 0.3358\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.8565              0.1359              0.8400\n",
      "Basal \t           0.2000              0.9713              0.1522              0.9643\n",
      "Her2 \t           0.2000              0.9187              0.0543              1.0000\n",
      "LumA \t           0.2000              0.5694              0.4837              0.0000\n",
      "LumB \t           0.2000              0.7847              0.1739              0.7500\n",
      "\n",
      "\n",
      "Test: Epoch 150\n",
      "Train Accuracy: 0.8766   Test ACC: 0.4783\n",
      "Train F1: 0.8748         Test F1: 0.3701\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9091              0.1359              0.8800\n",
      "Basal \t           0.2000              0.9569              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              0.9000\n",
      "LumA \t           0.2000              0.7225              0.4837              0.0225\n",
      "LumB \t           0.2000              0.7943              0.1739              0.8750\n",
      "\n",
      "\n",
      "Test: Epoch 200\n",
      "Train Accuracy: 0.8804   Test ACC: 0.4293\n",
      "Train F1: 0.8812         Test F1: 0.4158\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9043              0.1359              0.8800\n",
      "Basal \t           0.2000              0.9904              0.1522              0.9286\n",
      "Her2 \t           0.2000              0.8278              0.0543              1.0000\n",
      "LumA \t           0.2000              0.6986              0.4837              0.0899\n",
      "LumB \t           0.2000              0.9809              0.1739              0.4062\n",
      "\n",
      "\n",
      "Test: Epoch 250\n",
      "Train Accuracy: 0.9388   Test ACC: 0.6576\n",
      "Train F1: 0.9380         Test F1: 0.6549\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9282              0.1359              0.8800\n",
      "Basal \t           0.2000              0.9809              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              1.0000\n",
      "LumA \t           0.2000              0.8230              0.4837              0.3933\n",
      "LumB \t           0.2000              0.9617              0.1739              0.8438\n",
      "\n",
      "\n",
      "Test: Epoch 300\n",
      "Train Accuracy: 0.9397   Test ACC: 0.7717\n",
      "Train F1: 0.9392         Test F1: 0.7823\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9091              0.1359              0.8800\n",
      "Basal \t           0.2000              0.9856              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              1.0000\n",
      "LumA \t           0.2000              0.8325              0.4837              0.6292\n",
      "LumB \t           0.2000              0.9713              0.1739              0.8438\n",
      "\n",
      "\n",
      "Test: Epoch 350\n",
      "Train Accuracy: 0.9407   Test ACC: 0.7717\n",
      "Train F1: 0.9403         Test F1: 0.7804\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9234              0.1359              0.8800\n",
      "Basal \t           0.2000              0.9856              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              0.9000\n",
      "LumA \t           0.2000              0.8565              0.4837              0.6067\n",
      "LumB \t           0.2000              0.9378              0.1739              0.9375\n",
      "\n",
      "\n",
      "Test: Epoch 400\n",
      "Train Accuracy: 0.9388   Test ACC: 0.8315\n",
      "Train F1: 0.9382         Test F1: 0.8366\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9569              0.1359              0.8000\n",
      "Basal \t           0.2000              0.9809              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              0.9000\n",
      "LumA \t           0.2000              0.8182              0.4837              0.7753\n",
      "LumB \t           0.2000              0.9378              0.1739              0.8750\n",
      "\n",
      "\n",
      "Test: Epoch 450\n",
      "Train Accuracy: 0.9493   Test ACC: 0.8261\n",
      "Train F1: 0.9490         Test F1: 0.8323\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9569              0.1359              0.8000\n",
      "Basal \t           0.2000              0.9904              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              1.0000\n",
      "LumA \t           0.2000              0.8660              0.4837              0.7640\n",
      "LumB \t           0.2000              0.9330              0.1739              0.8438\n",
      "\n",
      "\n",
      "Test: Epoch 500\n",
      "Train Accuracy: 0.9493   Test ACC: 0.8478\n",
      "Train F1: 0.9491         Test F1: 0.8501\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9187              0.1359              0.8000\n",
      "Basal \t           0.2000              0.9809              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              1.0000\n",
      "LumA \t           0.2000              0.8995              0.4837              0.8427\n",
      "LumB \t           0.2000              0.9474              0.1739              0.7500\n",
      "\n",
      "\n",
      "Test: Epoch 550\n",
      "Train Accuracy: 0.9493   Test ACC: 0.7554\n",
      "Train F1: 0.9495         Test F1: 0.7637\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9282              0.1359              0.9200\n",
      "Basal \t           0.2000              0.9809              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              1.0000\n",
      "LumA \t           0.2000              0.9330              0.4837              0.5955\n",
      "LumB \t           0.2000              0.9043              0.1739              0.8125\n",
      "\n",
      "\n",
      "Test: Epoch 600\n",
      "Train Accuracy: 0.9522   Test ACC: 0.8424\n",
      "Train F1: 0.9516         Test F1: 0.8436\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9856              0.1359              0.7200\n",
      "Basal \t           0.2000              0.9713              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              1.0000\n",
      "LumA \t           0.2000              0.8421              0.4837              0.8652\n",
      "LumB \t           0.2000              0.9617              0.1739              0.7188\n",
      "\n",
      "\n",
      "Test: Epoch 650\n",
      "Train Accuracy: 0.9416   Test ACC: 0.8533\n",
      "Train F1: 0.9406         Test F1: 0.8569\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9665              0.1359              0.8400\n",
      "Basal \t           0.2000              0.9761              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              0.9000\n",
      "LumA \t           0.2000              0.7751              0.4837              0.8315\n",
      "LumB \t           0.2000              0.9904              0.1739              0.8125\n",
      "\n",
      "\n",
      "Test: Epoch 700\n",
      "Train Accuracy: 0.9512   Test ACC: 0.8315\n",
      "Train F1: 0.9506         Test F1: 0.8335\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9617              0.1359              0.8000\n",
      "Basal \t           0.2000              0.9809              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              1.0000\n",
      "LumA \t           0.2000              0.8278              0.4837              0.8427\n",
      "LumB \t           0.2000              0.9856              0.1739              0.6562\n",
      "\n",
      "\n",
      "Test: Epoch 750\n",
      "Train Accuracy: 0.9579   Test ACC: 0.8315\n",
      "Train F1: 0.9578         Test F1: 0.8385\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9665              0.1359              0.8400\n",
      "Basal \t           0.2000              0.9809              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              0.9000\n",
      "LumA \t           0.2000              0.9187              0.4837              0.7528\n",
      "LumB \t           0.2000              0.9234              0.1739              0.9062\n",
      "\n",
      "\n",
      "Test: Epoch 800\n",
      "Train Accuracy: 0.9522   Test ACC: 0.8533\n",
      "Train F1: 0.9522         Test F1: 0.8597\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9330              0.1359              0.8800\n",
      "Basal \t           0.2000              0.9809              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              1.0000\n",
      "LumA \t           0.2000              0.9187              0.4837              0.8090\n",
      "LumB \t           0.2000              0.9282              0.1739              0.8125\n",
      "\n",
      "\n",
      "Test: Epoch 850\n",
      "Train Accuracy: 0.9617   Test ACC: 0.8696\n",
      "Train F1: 0.9617         Test F1: 0.8745\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9522              0.1359              0.8800\n",
      "Basal \t           0.2000              0.9809              0.1522              0.9643\n",
      "Her2 \t           0.2000              1.0000              0.0543              0.9000\n",
      "LumA \t           0.2000              0.9282              0.4837              0.8315\n",
      "LumB \t           0.2000              0.9474              0.1739              0.8750\n",
      "\n",
      "Performing feature extraction using LIME ...\n",
      "\n",
      "Average lime score =  0.4828239114171759 \n",
      " Standard deviation =  0.09279173326481654 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses_tcga, metrics_tcga, feature_imp_tcga, _ = train_model(load_list=load_list, label_dict=label_dict, \n",
    "                                                              GCN_names=GCN_names, COMBINER=COMBINER,\n",
    "        SEED=SEED, num_epoch=num_epoch, test_interval=test_interval, lr=lr, weight_decay=weight_decay, \n",
    "        dropout=dropout, adj_parameter=adj_parameter, VERBOSE=VERBOSE, doSMOTE = doSMOTE,\n",
    "        RUN_TITLE=RUN_TITLE, RUN_TITLE_SHORT=RUN_TITLE_SHORT,\n",
    "        OUTPUT_FILES=OUTPUT_FILES, MAKE_PLOTS=MAKE_PLOTS, feature_extract=feature_extract)\n",
    "\n",
    "losses_tcga.to_csv(\"losses_tcga.csv\")\n",
    "metrics_tcga.to_csv(\"metrics_tcga.csv\")\n",
    "feature_imp_tcga[\"lime\"].to_csv(\"tcga_features.csv\", index_label=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METABRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TITLE = \"METABRIC mRNA Expression\"\n",
    "RUN_TITLE_SHORT = \"metabric_mrna\"\n",
    "\n",
    "# pre-processed data\n",
    "mrna = \"../R/METABRIC/metabric_top1000.csv\"\n",
    "meta_csv = \"../R/METABRIC/PAM50_metabric.csv\"\n",
    "trte_partition_file = \"../R/METABRIC/trte_partition_metabric.txt\"\n",
    "\n",
    "load_list = [mrna, meta_csv, trte_partition_file]\n",
    "GCN_names = [\"mRNA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-22 04:25:24.475659 \n",
      "\n",
      "METABRIC mRNA Expression\n",
      "SEED =  42\n",
      "\n",
      "Training...\n",
      "\n",
      "Test: Epoch 0\n",
      "Train Accuracy: 0.1790   Test ACC: 0.2563\n",
      "Train F1: 0.1319         Test F1: 0.1049\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.0172              0.1508              0.0000\n",
      "Basal \t           0.2000              0.5558              0.2141              0.0000\n",
      "Her2 \t           0.2000              0.0794              0.1538              0.0000\n",
      "LumA \t           0.2000              0.0365              0.2563              1.0000\n",
      "LumB \t           0.2000              0.2060              0.2251              0.0000\n",
      "\n",
      "\n",
      "Test: Epoch 50\n",
      "Train Accuracy: 0.8382   Test ACC: 0.7256\n",
      "Train F1: 0.8388         Test F1: 0.7269\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.8155              0.1508              0.7467\n",
      "Basal \t           0.2000              0.8541              0.2141              0.6901\n",
      "Her2 \t           0.2000              0.9313              0.1538              0.6013\n",
      "LumA \t           0.2000              0.7275              0.2563              0.6627\n",
      "LumB \t           0.2000              0.8627              0.2251              0.9018\n",
      "\n",
      "\n",
      "Test: Epoch 100\n",
      "Train Accuracy: 0.8798   Test ACC: 0.7347\n",
      "Train F1: 0.8799         Test F1: 0.7352\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.8970              0.1508              0.6933\n",
      "Basal \t           0.2000              0.9099              0.2141              0.6714\n",
      "Her2 \t           0.2000              0.9421              0.1538              0.5752\n",
      "LumA \t           0.2000              0.7811              0.2563              0.8196\n",
      "LumB \t           0.2000              0.8691              0.2251              0.8348\n",
      "\n",
      "\n",
      "Test: Epoch 150\n",
      "Train Accuracy: 0.9124   Test ACC: 0.7327\n",
      "Train F1: 0.9118         Test F1: 0.7320\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9549              0.1508              0.6067\n",
      "Basal \t           0.2000              0.9442              0.2141              0.6761\n",
      "Her2 \t           0.2000              0.9592              0.1538              0.6013\n",
      "LumA \t           0.2000              0.7876              0.2563              0.9176\n",
      "LumB \t           0.2000              0.9163              0.2251              0.7500\n",
      "\n",
      "\n",
      "Test: Epoch 200\n",
      "Train Accuracy: 0.9262   Test ACC: 0.7276\n",
      "Train F1: 0.9254         Test F1: 0.7271\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9657              0.1508              0.5933\n",
      "Basal \t           0.2000              0.9485              0.2141              0.6854\n",
      "Her2 \t           0.2000              0.9828              0.1538              0.5948\n",
      "LumA \t           0.2000              0.8047              0.2563              0.9333\n",
      "LumB \t           0.2000              0.9292              0.2251              0.7143\n",
      "\n",
      "\n",
      "Test: Epoch 250\n",
      "Train Accuracy: 0.9369   Test ACC: 0.7146\n",
      "Train F1: 0.9361         Test F1: 0.7137\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9871              0.1508              0.5267\n",
      "Basal \t           0.2000              0.9571              0.2141              0.6995\n",
      "Her2 \t           0.2000              0.9828              0.1538              0.5817\n",
      "LumA \t           0.2000              0.8047              0.2563              0.9529\n",
      "LumB \t           0.2000              0.9528              0.2251              0.6741\n",
      "\n",
      "\n",
      "Test: Epoch 300\n",
      "Train Accuracy: 0.9545   Test ACC: 0.7477\n",
      "Train F1: 0.9545         Test F1: 0.7451\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9785              0.1508              0.5933\n",
      "Basal \t           0.2000              0.9742              0.2141              0.6667\n",
      "Her2 \t           0.2000              0.9828              0.1538              0.5948\n",
      "LumA \t           0.2000              0.9313              0.2563              0.9059\n",
      "LumB \t           0.2000              0.9056              0.2251              0.8527\n",
      "\n",
      "\n",
      "Test: Epoch 350\n",
      "Train Accuracy: 0.9455   Test ACC: 0.7166\n",
      "Train F1: 0.9447         Test F1: 0.7153\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9893              0.1508              0.5133\n",
      "Basal \t           0.2000              0.9549              0.2141              0.6901\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.5948\n",
      "LumA \t           0.2000              0.8133              0.2563              0.9490\n",
      "LumB \t           0.2000              0.9807              0.2251              0.6964\n",
      "\n",
      "\n",
      "Test: Epoch 400\n",
      "Train Accuracy: 0.9464   Test ACC: 0.7146\n",
      "Train F1: 0.9463         Test F1: 0.7130\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9635              0.1508              0.5133\n",
      "Basal \t           0.2000              0.9571              0.2141              0.6995\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.5752\n",
      "LumA \t           0.2000              0.9120              0.2563              0.9569\n",
      "LumB \t           0.2000              0.9099              0.2251              0.6830\n",
      "\n",
      "\n",
      "Test: Epoch 450\n",
      "Train Accuracy: 0.9567   Test ACC: 0.7226\n",
      "Train F1: 0.9563         Test F1: 0.7215\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9893              0.1508              0.5333\n",
      "Basal \t           0.2000              0.9700              0.2141              0.6854\n",
      "Her2 \t           0.2000              0.9871              0.1538              0.6078\n",
      "LumA \t           0.2000              0.8670              0.2563              0.9490\n",
      "LumB \t           0.2000              0.9700              0.2251              0.7054\n",
      "\n",
      "\n",
      "Test: Epoch 500\n",
      "Train Accuracy: 0.9579   Test ACC: 0.7317\n",
      "Train F1: 0.9579         Test F1: 0.7279\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9764              0.1508              0.5933\n",
      "Basal \t           0.2000              0.9700              0.2141              0.6761\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.5098\n",
      "LumA \t           0.2000              0.9292              0.2563              0.9216\n",
      "LumB \t           0.2000              0.9249              0.2251              0.8125\n",
      "\n",
      "\n",
      "Test: Epoch 550\n",
      "Train Accuracy: 0.9579   Test ACC: 0.7317\n",
      "Train F1: 0.9576         Test F1: 0.7308\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9871              0.1508              0.5667\n",
      "Basal \t           0.2000              0.9764              0.2141              0.6808\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.6144\n",
      "LumA \t           0.2000              0.8734              0.2563              0.9451\n",
      "LumB \t           0.2000              0.9635              0.2251              0.7277\n",
      "\n",
      "\n",
      "Test: Epoch 600\n",
      "Train Accuracy: 0.9597   Test ACC: 0.7307\n",
      "Train F1: 0.9593         Test F1: 0.7295\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9893              0.1508              0.5467\n",
      "Basal \t           0.2000              0.9742              0.2141              0.6854\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.6144\n",
      "LumA \t           0.2000              0.8712              0.2563              0.9490\n",
      "LumB \t           0.2000              0.9742              0.2251              0.7277\n",
      "\n",
      "\n",
      "Test: Epoch 650\n",
      "Train Accuracy: 0.9498   Test ACC: 0.7146\n",
      "Train F1: 0.9490         Test F1: 0.7133\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9893              0.1508              0.4733\n",
      "Basal \t           0.2000              0.9700              0.2141              0.7042\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.6013\n",
      "LumA \t           0.2000              0.8219              0.2563              0.9608\n",
      "LumB \t           0.2000              0.9785              0.2251              0.6830\n",
      "\n",
      "\n",
      "Test: Epoch 700\n",
      "Train Accuracy: 0.9554   Test ACC: 0.7196\n",
      "Train F1: 0.9548         Test F1: 0.7181\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9893              0.1508              0.5000\n",
      "Basal \t           0.2000              0.9742              0.2141              0.6854\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.6144\n",
      "LumA \t           0.2000              0.8455              0.2563              0.9569\n",
      "LumB \t           0.2000              0.9785              0.2251              0.7009\n",
      "\n",
      "\n",
      "Test: Epoch 750\n",
      "Train Accuracy: 0.9639   Test ACC: 0.7357\n",
      "Train F1: 0.9639         Test F1: 0.7322\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9764              0.1508              0.6200\n",
      "Basal \t           0.2000              0.9742              0.2141              0.6761\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.5098\n",
      "LumA \t           0.2000              0.9442              0.2563              0.9137\n",
      "LumB \t           0.2000              0.9356              0.2251              0.8214\n",
      "\n",
      "\n",
      "Test: Epoch 800\n",
      "Train Accuracy: 0.9644   Test ACC: 0.7276\n",
      "Train F1: 0.9643         Test F1: 0.7255\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9850              0.1508              0.5600\n",
      "Basal \t           0.2000              0.9721              0.2141              0.6854\n",
      "Her2 \t           0.2000              0.9871              0.1538              0.5621\n",
      "LumA \t           0.2000              0.9163              0.2563              0.9529\n",
      "LumB \t           0.2000              0.9614              0.2251              0.7366\n",
      "\n",
      "\n",
      "Test: Epoch 850\n",
      "Train Accuracy: 0.9592   Test ACC: 0.7337\n",
      "Train F1: 0.9591         Test F1: 0.7304\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9764              0.1508              0.5600\n",
      "Basal \t           0.2000              0.9678              0.2141              0.7042\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.5294\n",
      "LumA \t           0.2000              0.9206              0.2563              0.9294\n",
      "LumB \t           0.2000              0.9421              0.2251              0.7946\n",
      "\n",
      "Performing feature extraction using LIME ...\n",
      "\n",
      "Average lime score =  0.4618347570709971 \n",
      " Standard deviation =  0.10181098278833527 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses_metabric, metrics_metabric, feature_imp_metabric, _ = train_model(load_list=load_list, label_dict=label_dict, \n",
    "                                                              GCN_names=GCN_names, COMBINER=COMBINER,\n",
    "        SEED=SEED, num_epoch=num_epoch, test_interval=test_interval, lr=lr, weight_decay=weight_decay, \n",
    "        dropout=dropout, adj_parameter=adj_parameter, VERBOSE=VERBOSE, doSMOTE = doSMOTE,\n",
    "        RUN_TITLE=RUN_TITLE, RUN_TITLE_SHORT=RUN_TITLE_SHORT,\n",
    "        OUTPUT_FILES=OUTPUT_FILES, MAKE_PLOTS=MAKE_PLOTS, feature_extract=feature_extract)\n",
    "\n",
    "losses_metabric.to_csv(\"losses_metabric.csv\")\n",
    "metrics_metabric.to_csv(\"metrics_metabric.csv\")\n",
    "feature_imp_metabric[\"lime\"].to_csv(\"metabric_features.csv\", index_label=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tcga = \n",
    "# metabric = \n",
    "# renaming the \"lime scores\" column to tcga and metabric\n",
    "\n",
    "# Common biomarkers (out of the thousand each)\n",
    "# biomarkers = inner_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection of the 1000 best features selected\n",
    "# len(biomarkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of the common biomarkers\n",
    "# Pearson correlation\n",
    "# Spearman correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Testing on Independent Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will train the model on TCGA BRCA data and then validate the model on METABRIC data. To ensure that the feature set is the same in both the data sets, I have selected the best features using ANOVA on the BRCA data set and then removed the features not found in the METABRIC data set. This results in only removal of 5% of the originally selected features from the BRCA data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary libraries and functions\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from main import train_model\n",
    "import pandas as pd\n",
    "\n",
    "# Setting all variables for run\n",
    "# SEED can be \"random\" or integer, if integer, it will be used as the seed for random, numpy, torch, and cuda\n",
    "SEED = \"random\"\n",
    "\n",
    "# change label from text to integer\n",
    "label_dict = {'Normal':0, 'Basal':1, 'Her2':2, 'LumA':3, 'LumB':4}\n",
    "\n",
    "COMBINER = False \n",
    "doSMOTE = True \n",
    "\n",
    "# Training parameters\n",
    "num_epoch = 1000\n",
    "test_interval = 50\n",
    "lr = 5e-5\n",
    "weight_decay = 5e-4\n",
    "dropout = 0.50\n",
    "adj_parameter = 5 # average number of edge per node in adj matrix\n",
    "\n",
    "VERBOSE = 1 #0, only print final result; 1, only testing result; 2, training and testing result\n",
    "OUTPUT_FILES = False #Boolean to determine whether to output loss and metrics as csv files\n",
    "MAKE_PLOTS = False #Boolean to determine whether to output loss and metrics as plots in png format\n",
    "feature_extract = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TITLE = \"TCGA Training & METABRIC Testing: mRNA Expression\"\n",
    "RUN_TITLE_SHORT = \"tcga_metabric\"\n",
    "\n",
    "# pre-processed data\n",
    "mrna = \"../R/METABRIC/tcga_metabric_mrna.csv\"\n",
    "meta_csv = \"../R/METABRIC/PAM50_tcga_metabric.csv\"\n",
    "trte_partition_file = \"../R/METABRIC/trte_partition_tcga_metabric.txt\"\n",
    "\n",
    "load_list = [mrna, meta_csv, trte_partition_file]\n",
    "GCN_names = [\"mRNA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 13:46:58.506702 \n",
      "\n",
      "TCGA Training & METABRIC Testing: mRNA Expression\n",
      "SEED =  83810\n",
      "\n",
      "Training...\n",
      "\n",
      "Test: Epoch 0\n",
      "Train Accuracy: 0.1805   Test ACC: 0.1978\n",
      "Train F1: 0.1599         Test F1: 0.1141\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.0268              0.1044              0.0577\n",
      "Basal \t           0.2000              0.1007              0.1662              0.0937\n",
      "Her2 \t           0.2000              0.1577              0.1205              0.0000\n",
      "LumA \t           0.2000              0.3691              0.3619              0.0014\n",
      "LumB \t           0.2000              0.2483              0.2470              0.7114\n",
      "\n",
      "\n",
      "Test: Epoch 50\n",
      "Train Accuracy: 0.5315   Test ACC: 0.2359\n",
      "Train F1: 0.5245         Test F1: 0.1774\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.7181              0.1044              0.4231\n",
      "Basal \t           0.2000              0.6174              0.1662              0.3686\n",
      "Her2 \t           0.2000              0.4430              0.1205              0.9917\n",
      "LumA \t           0.2000              0.5503              0.3619              0.0000\n",
      "LumB \t           0.2000              0.3289              0.2470              0.0447\n",
      "\n",
      "\n",
      "Test: Epoch 100\n",
      "Train Accuracy: 0.7503   Test ACC: 0.3258\n",
      "Train F1: 0.7458         Test F1: 0.2994\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.8624              0.1044              0.4231\n",
      "Basal \t           0.2000              0.9161              0.1662              0.7039\n",
      "Her2 \t           0.2000              0.7886              0.1205              0.9625\n",
      "LumA \t           0.2000              0.6711              0.3619              0.0347\n",
      "LumB \t           0.2000              0.5134              0.2470              0.1463\n",
      "\n",
      "\n",
      "Test: Epoch 150\n",
      "Train Accuracy: 0.8403   Test ACC: 0.6461\n",
      "Train F1: 0.8378         Test F1: 0.6161\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9027              0.1044              0.3942\n",
      "Basal \t           0.2000              0.9832              0.1662              0.8248\n",
      "Her2 \t           0.2000              0.8859              0.1205              0.7792\n",
      "LumA \t           0.2000              0.7282              0.3619              0.8807\n",
      "LumB \t           0.2000              0.7013              0.2470              0.2236\n",
      "\n",
      "\n",
      "Test: Epoch 200\n",
      "Train Accuracy: 0.8819   Test ACC: 0.6461\n",
      "Train F1: 0.8806         Test F1: 0.6115\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9128              0.1044              0.4279\n",
      "Basal \t           0.2000              0.9933              0.1662              0.7251\n",
      "Her2 \t           0.2000              0.9362              0.1205              0.8167\n",
      "LumA \t           0.2000              0.7886              0.3619              0.9196\n",
      "LumB \t           0.2000              0.7785              0.2470              0.2012\n",
      "\n",
      "\n",
      "Test: Epoch 250\n",
      "Train Accuracy: 0.9040   Test ACC: 0.6526\n",
      "Train F1: 0.9032         Test F1: 0.6209\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9262              0.1044              0.4471\n",
      "Basal \t           0.2000              0.9832              0.1662              0.7372\n",
      "Her2 \t           0.2000              0.9698              0.1205              0.8250\n",
      "LumA \t           0.2000              0.7886              0.3619              0.9126\n",
      "LumB \t           0.2000              0.8523              0.2470              0.2175\n",
      "\n",
      "\n",
      "Test: Epoch 300\n",
      "Train Accuracy: 0.9081   Test ACC: 0.6260\n",
      "Train F1: 0.9070         Test F1: 0.5868\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9262              0.1044              0.3558\n",
      "Basal \t           0.2000              0.9899              0.1662              0.6918\n",
      "Her2 \t           0.2000              0.9933              0.1205              0.8417\n",
      "LumA \t           0.2000              0.8020              0.3619              0.9140\n",
      "LumB \t           0.2000              0.8289              0.2470              0.1687\n",
      "\n",
      "\n",
      "Test: Epoch 350\n",
      "Train Accuracy: 0.9128   Test ACC: 0.6536\n",
      "Train F1: 0.9122         Test F1: 0.6277\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9094              0.1044              0.3221\n",
      "Basal \t           0.2000              0.9899              0.1662              0.7100\n",
      "Her2 \t           0.2000              0.9866              0.1205              0.8333\n",
      "LumA \t           0.2000              0.8289              0.3619              0.9182\n",
      "LumB \t           0.2000              0.8490              0.2470              0.2805\n",
      "\n",
      "\n",
      "Test: Epoch 400\n",
      "Train Accuracy: 0.9242   Test ACC: 0.6260\n",
      "Train F1: 0.9234         Test F1: 0.6094\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9161              0.1044              0.3990\n",
      "Basal \t           0.2000              0.9899              0.1662              0.6465\n",
      "Her2 \t           0.2000              0.9966              0.1205              0.8625\n",
      "LumA \t           0.2000              0.8121              0.3619              0.8571\n",
      "LumB \t           0.2000              0.9060              0.2470              0.2541\n",
      "\n",
      "\n",
      "Test: Epoch 450\n",
      "Train Accuracy: 0.9309   Test ACC: 0.6285\n",
      "Train F1: 0.9303         Test F1: 0.6130\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9329              0.1044              0.3606\n",
      "Basal \t           0.2000              0.9866              0.1662              0.5861\n",
      "Her2 \t           0.2000              0.9933              0.1205              0.8625\n",
      "LumA \t           0.2000              0.8322              0.3619              0.8779\n",
      "LumB \t           0.2000              0.9094              0.2470              0.2907\n",
      "\n",
      "\n",
      "Test: Epoch 500\n",
      "Train Accuracy: 0.9423   Test ACC: 0.6180\n",
      "Train F1: 0.9420         Test F1: 0.6033\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9362              0.1044              0.3365\n",
      "Basal \t           0.2000              0.9899              0.1662              0.5347\n",
      "Her2 \t           0.2000              0.9933              0.1205              0.8625\n",
      "LumA \t           0.2000              0.8456              0.3619              0.8766\n",
      "LumB \t           0.2000              0.9463              0.2470              0.2947\n",
      "\n",
      "\n",
      "Test: Epoch 550\n",
      "Train Accuracy: 0.9383   Test ACC: 0.6426\n",
      "Train F1: 0.9378         Test F1: 0.6300\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9362              0.1044              0.3365\n",
      "Basal \t           0.2000              0.9866              0.1662              0.5650\n",
      "Her2 \t           0.2000              0.9966              0.1205              0.8458\n",
      "LumA \t           0.2000              0.8289              0.3619              0.8849\n",
      "LumB \t           0.2000              0.9430              0.2470              0.3699\n",
      "\n",
      "\n",
      "Test: Epoch 600\n",
      "Train Accuracy: 0.9409   Test ACC: 0.6235\n",
      "Train F1: 0.9405         Test F1: 0.6059\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9362              0.1044              0.3413\n",
      "Basal \t           0.2000              0.9866              0.1662              0.5619\n",
      "Her2 \t           0.2000              1.0000              0.1205              0.8583\n",
      "LumA \t           0.2000              0.8591              0.3619              0.8835\n",
      "LumB \t           0.2000              0.9228              0.2470              0.2886\n",
      "\n",
      "\n",
      "Test: Epoch 650\n",
      "Train Accuracy: 0.9403   Test ACC: 0.5934\n",
      "Train F1: 0.9399         Test F1: 0.5797\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9329              0.1044              0.3413\n",
      "Basal \t           0.2000              0.9899              0.1662              0.4834\n",
      "Her2 \t           0.2000              1.0000              0.1205              0.8625\n",
      "LumA \t           0.2000              0.8490              0.3619              0.8571\n",
      "LumB \t           0.2000              0.9295              0.2470              0.2561\n",
      "\n",
      "\n",
      "Test: Epoch 700\n",
      "Train Accuracy: 0.9483   Test ACC: 0.5989\n",
      "Train F1: 0.9481         Test F1: 0.5765\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9329              0.1044              0.3221\n",
      "Basal \t           0.2000              0.9899              0.1662              0.4894\n",
      "Her2 \t           0.2000              1.0000              0.1205              0.8583\n",
      "LumA \t           0.2000              0.8758              0.3619              0.8821\n",
      "LumB \t           0.2000              0.9430              0.2470              0.2480\n",
      "\n",
      "\n",
      "Test: Epoch 750\n",
      "Train Accuracy: 0.9483   Test ACC: 0.5899\n",
      "Train F1: 0.9480         Test F1: 0.5604\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9564              0.1044              0.2981\n",
      "Basal \t           0.2000              0.9933              0.1662              0.4320\n",
      "Her2 \t           0.2000              0.9966              0.1205              0.8583\n",
      "LumA \t           0.2000              0.8490              0.3619              0.9029\n",
      "LumB \t           0.2000              0.9463              0.2470              0.2297\n",
      "\n",
      "\n",
      "Test: Epoch 800\n",
      "Train Accuracy: 0.9450   Test ACC: 0.6009\n",
      "Train F1: 0.9446         Test F1: 0.5688\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9463              0.1044              0.3269\n",
      "Basal \t           0.2000              0.9899              0.1662              0.4894\n",
      "Her2 \t           0.2000              1.0000              0.1205              0.8583\n",
      "LumA \t           0.2000              0.8624              0.3619              0.9140\n",
      "LumB \t           0.2000              0.9262              0.2470              0.2073\n",
      "\n",
      "\n",
      "Test: Epoch 850\n",
      "Train Accuracy: 0.9523   Test ACC: 0.5909\n",
      "Train F1: 0.9521         Test F1: 0.5618\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9430              0.1044              0.3269\n",
      "Basal \t           0.2000              0.9899              0.1662              0.4622\n",
      "Her2 \t           0.2000              1.0000              0.1205              0.8583\n",
      "LumA \t           0.2000              0.8859              0.3619              0.8974\n",
      "LumB \t           0.2000              0.9430              0.2470              0.2093\n",
      "\n",
      "\n",
      "Test: Epoch 900\n",
      "Train Accuracy: 0.9570   Test ACC: 0.5984\n",
      "Train F1: 0.9568         Test F1: 0.5537\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9463              0.1044              0.2933\n",
      "Basal \t           0.2000              0.9899              0.1662              0.5015\n",
      "Her2 \t           0.2000              1.0000              0.1205              0.8417\n",
      "LumA \t           0.2000              0.8893              0.3619              0.9459\n",
      "LumB \t           0.2000              0.9597              0.2470              0.1646\n",
      "\n",
      "\n",
      "Test: Epoch 950\n",
      "Train Accuracy: 0.9510   Test ACC: 0.5919\n",
      "Train F1: 0.9507         Test F1: 0.5501\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9497              0.1044              0.2837\n",
      "Basal \t           0.2000              0.9899              0.1662              0.4924\n",
      "Her2 \t           0.2000              1.0000              0.1205              0.8583\n",
      "LumA \t           0.2000              0.8658              0.3619              0.9279\n",
      "LumB \t           0.2000              0.9497              0.2470              0.1667\n",
      "\n",
      "\n",
      "Test: Epoch 1000\n",
      "Train Accuracy: 0.9570   Test ACC: 0.5863\n",
      "Train F1: 0.9568         Test F1: 0.5411\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9597              0.1044              0.3173\n",
      "Basal \t           0.2000              0.9899              0.1662              0.4532\n",
      "Her2 \t           0.2000              1.0000              0.1205              0.8542\n",
      "LumA \t           0.2000              0.8725              0.3619              0.9334\n",
      "LumB \t           0.2000              0.9631              0.2470              0.1504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses_tcga_metabric, metrics_tcga_metabric, features_tcga_metabric, _ = train_model(load_list=load_list, label_dict=label_dict, \n",
    "                                                              GCN_names=GCN_names, COMBINER=COMBINER,\n",
    "        SEED=SEED, num_epoch=num_epoch, test_interval=test_interval, lr=lr, weight_decay=weight_decay, \n",
    "        dropout=dropout, adj_parameter=adj_parameter, VERBOSE=VERBOSE, doSMOTE = doSMOTE,\n",
    "        RUN_TITLE=RUN_TITLE, RUN_TITLE_SHORT=RUN_TITLE_SHORT,\n",
    "        OUTPUT_FILES=OUTPUT_FILES, MAKE_PLOTS=MAKE_PLOTS, feature_extract=feature_extract)\n",
    "\n",
    "losses_tcga_metabric.to_csv(\"losses_tcga_metabric.csv\")\n",
    "metrics_tcga_metabric.to_csv(\"metrics_tcga_metabric.csv\")\n",
    "#feature_tcga_metabric[\"lime\"].to_csv(\"tcga_metabric_features.csv\", index_label=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#metrics_tcga_metabric.head()\n",
    "metrics_tcga_metabric.plot(y = [\"train_F1\", \"train_accuracy\", \"test_F1\", \"test_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: METABRIC, but with features pre-selected from TCGA BRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary libraries and functions\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from main import train_model\n",
    "import pandas as pd\n",
    "\n",
    "# Setting all variables for run\n",
    "# SEED can be \"random\" or integer, if integer, it will be used as the seed for random, numpy, torch, and cuda\n",
    "SEED = 42 \n",
    "\n",
    "# change label from text to integer\n",
    "label_dict = {'Normal':0, 'Basal':1, 'Her2':2, 'LumA':3, 'LumB':4}\n",
    "\n",
    "COMBINER = False \n",
    "doSMOTE = True \n",
    "\n",
    "# Training parameters\n",
    "num_epoch = 500\n",
    "test_interval = 25\n",
    "lr = 5e-4\n",
    "weight_decay = 5e-4\n",
    "dropout = 0.5\n",
    "adj_parameter = 8 # average number of edge per node in adj matrix\n",
    "\n",
    "VERBOSE = 1 #0, only print final result; 1, only testing result; 2, training and testing result\n",
    "OUTPUT_FILES = False #Boolean to determine whether to output loss and metrics as csv files\n",
    "MAKE_PLOTS = False #Boolean to determine whether to output loss and metrics as plots in png format\n",
    "REPEATS = 1 #Integer, how many times to independently train the model\n",
    "feature_extract = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_TITLE = \"METABRIC mRNA Expression, but with TCGA BRCA features\"\n",
    "RUN_TITLE_SHORT = \"metabric_mrna\"\n",
    "\n",
    "# pre-processed data\n",
    "mrna = \"../R/METABRIC/metabric_mrna_common_genes.csv\"\n",
    "meta_csv = \"../R/METABRIC/PAM50_metabric.csv\"\n",
    "trte_partition_file = \"../R/METABRIC/trte_partition_metabric.txt\"\n",
    "\n",
    "load_list = [mrna, meta_csv, trte_partition_file]\n",
    "GCN_names = [\"mRNA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-01 23:40:58.091837 \n",
      "\n",
      "METABRIC mRNA Expression, but with TCGABRCA features\n",
      "SEED =  42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n",
      "\n",
      "Test: Epoch 0\n",
      "Train Accuracy: 0.2094   Test ACC: 0.2563\n",
      "Train F1: 0.1580         Test F1: 0.1046\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.5451              0.1508              0.0000\n",
      "Basal \t           0.2000              0.1137              0.2141              0.0000\n",
      "Her2 \t           0.2000              0.3412              0.1538              0.0000\n",
      "LumA \t           0.2000              0.0258              0.2563              1.0000\n",
      "LumB \t           0.2000              0.0215              0.2251              0.0000\n",
      "\n",
      "\n",
      "Test: Epoch 25\n",
      "Train Accuracy: 0.5146   Test ACC: 0.5588\n",
      "Train F1: 0.4917         Test F1: 0.5375\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.4442              0.1508              0.8933\n",
      "Basal \t           0.2000              0.9270              0.2141              0.8404\n",
      "Her2 \t           0.2000              0.2296              0.1538              0.5948\n",
      "LumA \t           0.2000              0.5408              0.2563              0.1059\n",
      "LumB \t           0.2000              0.4313              0.2251              0.5580\n",
      "\n",
      "\n",
      "Test: Epoch 50\n",
      "Train Accuracy: 0.7601   Test ACC: 0.6603\n",
      "Train F1: 0.7549         Test F1: 0.6462\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.7961              0.1508              0.8667\n",
      "Basal \t           0.2000              0.9764              0.2141              0.7700\n",
      "Her2 \t           0.2000              0.7811              0.1538              0.7582\n",
      "LumA \t           0.2000              0.6931              0.2563              0.2549\n",
      "LumB \t           0.2000              0.5536              0.2251              0.8125\n",
      "\n",
      "\n",
      "Test: Epoch 75\n",
      "Train Accuracy: 0.8382   Test ACC: 0.6633\n",
      "Train F1: 0.8347         Test F1: 0.6461\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.8455              0.1508              0.8533\n",
      "Basal \t           0.2000              0.9614              0.2141              0.7324\n",
      "Her2 \t           0.2000              0.9678              0.1538              0.7124\n",
      "LumA \t           0.2000              0.6202              0.2563              0.2627\n",
      "LumB \t           0.2000              0.7961              0.2251              0.8929\n",
      "\n",
      "\n",
      "Test: Epoch 100\n",
      "Train Accuracy: 0.8670   Test ACC: 0.7025\n",
      "Train F1: 0.8641         Test F1: 0.7064\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9013              0.1508              0.8467\n",
      "Basal \t           0.2000              0.9657              0.2141              0.6432\n",
      "Her2 \t           0.2000              0.9678              0.1538              0.6928\n",
      "LumA \t           0.2000              0.6609              0.2563              0.5725\n",
      "LumB \t           0.2000              0.8391              0.2251              0.8170\n",
      "\n",
      "\n",
      "Test: Epoch 125\n",
      "Train Accuracy: 0.8858   Test ACC: 0.7337\n",
      "Train F1: 0.8842         Test F1: 0.7366\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9421              0.1508              0.7800\n",
      "Basal \t           0.2000              0.9528              0.2141              0.6948\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.6601\n",
      "LumA \t           0.2000              0.7511              0.2563              0.6706\n",
      "LumB \t           0.2000              0.7940              0.2251              0.8616\n",
      "\n",
      "\n",
      "Test: Epoch 150\n",
      "Train Accuracy: 0.8948   Test ACC: 0.7337\n",
      "Train F1: 0.8933         Test F1: 0.7369\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9592              0.1508              0.7867\n",
      "Basal \t           0.2000              0.9721              0.2141              0.6714\n",
      "Her2 \t           0.2000              0.9700              0.1538              0.6536\n",
      "LumA \t           0.2000              0.7403              0.2563              0.7176\n",
      "LumB \t           0.2000              0.8326              0.2251              0.8304\n",
      "\n",
      "\n",
      "Test: Epoch 175\n",
      "Train Accuracy: 0.8906   Test ACC: 0.7176\n",
      "Train F1: 0.8874         Test F1: 0.7206\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9421              0.1508              0.7533\n",
      "Basal \t           0.2000              0.9485              0.2141              0.6761\n",
      "Her2 \t           0.2000              0.9936              0.1538              0.5686\n",
      "LumA \t           0.2000              0.6588              0.2563              0.7294\n",
      "LumB \t           0.2000              0.9099              0.2251              0.8214\n",
      "\n",
      "\n",
      "Test: Epoch 200\n",
      "Train Accuracy: 0.9013   Test ACC: 0.7065\n",
      "Train F1: 0.8984         Test F1: 0.7089\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9506              0.1508              0.6000\n",
      "Basal \t           0.2000              0.9657              0.2141              0.6714\n",
      "Her2 \t           0.2000              0.9914              0.1538              0.6405\n",
      "LumA \t           0.2000              0.6738              0.2563              0.8745\n",
      "LumB \t           0.2000              0.9249              0.2251              0.6652\n",
      "\n",
      "\n",
      "Test: Epoch 225\n",
      "Train Accuracy: 0.9052   Test ACC: 0.7106\n",
      "Train F1: 0.9024         Test F1: 0.7117\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9807              0.1508              0.5333\n",
      "Basal \t           0.2000              0.9721              0.2141              0.6808\n",
      "Her2 \t           0.2000              0.9807              0.1538              0.6601\n",
      "LumA \t           0.2000              0.6910              0.2563              0.8392\n",
      "LumB \t           0.2000              0.9013              0.2251              0.7455\n",
      "\n",
      "\n",
      "Test: Epoch 250\n",
      "Train Accuracy: 0.9137   Test ACC: 0.7216\n",
      "Train F1: 0.9125         Test F1: 0.7242\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9528              0.1508              0.7467\n",
      "Basal \t           0.2000              0.9657              0.2141              0.6854\n",
      "Her2 \t           0.2000              0.9936              0.1538              0.5490\n",
      "LumA \t           0.2000              0.7618              0.2563              0.7412\n",
      "LumB \t           0.2000              0.8948              0.2251              0.8348\n",
      "\n",
      "\n",
      "Test: Epoch 275\n",
      "Train Accuracy: 0.9245   Test ACC: 0.7126\n",
      "Train F1: 0.9237         Test F1: 0.7132\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9721              0.1508              0.5333\n",
      "Basal \t           0.2000              0.9700              0.2141              0.6808\n",
      "Her2 \t           0.2000              0.9828              0.1538              0.6340\n",
      "LumA \t           0.2000              0.8219              0.2563              0.8549\n",
      "LumB \t           0.2000              0.8755              0.2251              0.7545\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test: Epoch 300\n",
      "Train Accuracy: 0.9258   Test ACC: 0.7005\n",
      "Train F1: 0.9253         Test F1: 0.7019\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9528              0.1508              0.5600\n",
      "Basal \t           0.2000              0.9742              0.2141              0.6808\n",
      "Her2 \t           0.2000              0.9914              0.1538              0.5817\n",
      "LumA \t           0.2000              0.8197              0.2563              0.9059\n",
      "LumB \t           0.2000              0.8906              0.2251              0.6607\n",
      "\n",
      "\n",
      "Test: Epoch 325\n",
      "Train Accuracy: 0.9391   Test ACC: 0.7085\n",
      "Train F1: 0.9387         Test F1: 0.7099\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9678              0.1508              0.6133\n",
      "Basal \t           0.2000              0.9742              0.2141              0.6714\n",
      "Her2 \t           0.2000              0.9936              0.1538              0.5621\n",
      "LumA \t           0.2000              0.8627              0.2563              0.7255\n",
      "LumB \t           0.2000              0.8970              0.2251              0.8884\n",
      "\n",
      "\n",
      "Test: Epoch 350\n",
      "Train Accuracy: 0.9356   Test ACC: 0.7186\n",
      "Train F1: 0.9348         Test F1: 0.7189\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9957              0.1508              0.5400\n",
      "Basal \t           0.2000              0.9807              0.2141              0.6761\n",
      "Her2 \t           0.2000              0.9657              0.1538              0.6667\n",
      "LumA \t           0.2000              0.7833              0.2563              0.8784\n",
      "LumB \t           0.2000              0.9528              0.2251              0.7321\n",
      "\n",
      "\n",
      "Test: Epoch 375\n",
      "Train Accuracy: 0.9348   Test ACC: 0.7176\n",
      "Train F1: 0.9333         Test F1: 0.7209\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9785              0.1508              0.7000\n",
      "Basal \t           0.2000              0.9850              0.2141              0.6620\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.6275\n",
      "LumA \t           0.2000              0.7554              0.2563              0.8157\n",
      "LumB \t           0.2000              0.9657              0.2251              0.7321\n",
      "\n",
      "\n",
      "Test: Epoch 400\n",
      "Train Accuracy: 0.9399   Test ACC: 0.7206\n",
      "Train F1: 0.9392         Test F1: 0.7227\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9871              0.1508              0.5933\n",
      "Basal \t           0.2000              0.9700              0.2141              0.6854\n",
      "Her2 \t           0.2000              0.9871              0.1538              0.6275\n",
      "LumA \t           0.2000              0.8133              0.2563              0.8392\n",
      "LumB \t           0.2000              0.9421              0.2251              0.7679\n",
      "\n",
      "\n",
      "Test: Epoch 425\n",
      "Train Accuracy: 0.9494   Test ACC: 0.7015\n",
      "Train F1: 0.9492         Test F1: 0.7004\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9635              0.1508              0.5333\n",
      "Basal \t           0.2000              0.9850              0.2141              0.6432\n",
      "Her2 \t           0.2000              0.9914              0.1538              0.7320\n",
      "LumA \t           0.2000              0.8712              0.2563              0.9373\n",
      "LumB \t           0.2000              0.9356              0.2251              0.5804\n",
      "\n",
      "\n",
      "Test: Epoch 450\n",
      "Train Accuracy: 0.9506   Test ACC: 0.7266\n",
      "Train F1: 0.9501         Test F1: 0.7287\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9871              0.1508              0.6467\n",
      "Basal \t           0.2000              0.9807              0.2141              0.6667\n",
      "Her2 \t           0.2000              0.9914              0.1538              0.6405\n",
      "LumA \t           0.2000              0.8476              0.2563              0.8235\n",
      "LumB \t           0.2000              0.9464              0.2251              0.7857\n",
      "\n",
      "\n",
      "Test: Epoch 475\n",
      "Train Accuracy: 0.9511   Test ACC: 0.7276\n",
      "Train F1: 0.9508         Test F1: 0.7296\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9871              0.1508              0.7667\n",
      "Basal \t           0.2000              0.9785              0.2141              0.6714\n",
      "Her2 \t           0.2000              0.9957              0.1538              0.6013\n",
      "LumA \t           0.2000              0.8798              0.2563              0.6549\n",
      "LumB \t           0.2000              0.9142              0.2251              0.9241\n",
      "\n",
      "\n",
      "Test: Epoch 500\n",
      "Train Accuracy: 0.9571   Test ACC: 0.7206\n",
      "Train F1: 0.9570         Test F1: 0.7221\n",
      "\n",
      "Label        Train Distribution     Train Accuracy     Test Distribution     Test Accuracy\n",
      "------------------------------------------------------------------------------------------\n",
      "Normal \t           0.2000              0.9871              0.1508              0.7733\n",
      "Basal \t           0.2000              0.9807              0.2141              0.6667\n",
      "Her2 \t           0.2000              0.9893              0.1538              0.5752\n",
      "LumA \t           0.2000              0.9378              0.2563              0.6392\n",
      "LumB \t           0.2000              0.8906              0.2251              0.9286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses_metabric_preselected, metrics_metabric_preselected, _, _ = train_model(load_list=load_list, label_dict=label_dict, \n",
    "                                                              GCN_names=GCN_names, COMBINER=COMBINER,\n",
    "        SEED=SEED, num_epoch=num_epoch, test_interval=test_interval, lr=lr, weight_decay=weight_decay, \n",
    "        dropout=dropout, adj_parameter=adj_parameter, VERBOSE=VERBOSE, doSMOTE = doSMOTE,\n",
    "        RUN_TITLE=RUN_TITLE, RUN_TITLE_SHORT=RUN_TITLE_SHORT,\n",
    "        OUTPUT_FILES=OUTPUT_FILES, MAKE_PLOTS=MAKE_PLOTS, feature_extract=feature_extract)\n",
    "\n",
    "#losses_tcga_metabric.to_csv(\"losses_tcga_metabric.csv\")\n",
    "#metrics_tcga_metabric.to_csv(\"metrics_tcga_metabric.csv\")\n",
    "#feature_tcga_metabric[\"lime\"].to_csv(\"tcga_metabric_features.csv\", index_label=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics_metabric_preselected.plot(y = [\"train_F1\", \"train_accuracy\", \"test_F1\", \"test_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Testing on Independent Imputed Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will again train the model on TCGA BRCA data, but instead of training on only the single omics (gene expression) that is present in both data sets, I will use a modified METABRIC data set where the missing omics (DNA Methylation and miRNA expression) are imputed using the TCGA BRCA data. Thus, this will be a multi-omic validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "First we need to impute the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBF4|10926</th>\n",
       "      <th>DACH1|1602</th>\n",
       "      <th>BBS4|585</th>\n",
       "      <th>L3MBTL4|91133</th>\n",
       "      <th>TK1|7083</th>\n",
       "      <th>KIAA1370|56204</th>\n",
       "      <th>GPD1L|23171</th>\n",
       "      <th>RERG|85004</th>\n",
       "      <th>RAPGEF3|10411</th>\n",
       "      <th>FBXO36|130888</th>\n",
       "      <th>...</th>\n",
       "      <th>ANO10|55129</th>\n",
       "      <th>FDFT1|2222</th>\n",
       "      <th>MED6|10001</th>\n",
       "      <th>INCA1|388324</th>\n",
       "      <th>MYH9|4627</th>\n",
       "      <th>MYH14|79784</th>\n",
       "      <th>BTBD10|84280</th>\n",
       "      <th>ACTR3C|653857</th>\n",
       "      <th>KIAA0146|23514</th>\n",
       "      <th>BSDC1|55108</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-D8-A1XU-01</th>\n",
       "      <td>6.998086</td>\n",
       "      <td>10.125705</td>\n",
       "      <td>8.332896</td>\n",
       "      <td>4.537035</td>\n",
       "      <td>8.211207</td>\n",
       "      <td>10.111945</td>\n",
       "      <td>10.140800</td>\n",
       "      <td>12.116795</td>\n",
       "      <td>8.603795</td>\n",
       "      <td>8.009364</td>\n",
       "      <td>...</td>\n",
       "      <td>10.645044</td>\n",
       "      <td>11.479985</td>\n",
       "      <td>7.971973</td>\n",
       "      <td>4.004537</td>\n",
       "      <td>14.529590</td>\n",
       "      <td>11.192954</td>\n",
       "      <td>9.490083</td>\n",
       "      <td>5.848237</td>\n",
       "      <td>9.455163</td>\n",
       "      <td>11.069669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-D8-A1XV-01</th>\n",
       "      <td>8.117341</td>\n",
       "      <td>11.005011</td>\n",
       "      <td>9.888690</td>\n",
       "      <td>7.498527</td>\n",
       "      <td>9.495441</td>\n",
       "      <td>12.370753</td>\n",
       "      <td>10.892996</td>\n",
       "      <td>11.942934</td>\n",
       "      <td>7.569660</td>\n",
       "      <td>8.433369</td>\n",
       "      <td>...</td>\n",
       "      <td>9.554953</td>\n",
       "      <td>11.472607</td>\n",
       "      <td>8.678011</td>\n",
       "      <td>2.743644</td>\n",
       "      <td>13.900355</td>\n",
       "      <td>10.332066</td>\n",
       "      <td>9.084859</td>\n",
       "      <td>5.172484</td>\n",
       "      <td>9.365128</td>\n",
       "      <td>11.526008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-E9-A1N3-01</th>\n",
       "      <td>8.100588</td>\n",
       "      <td>13.055740</td>\n",
       "      <td>9.338570</td>\n",
       "      <td>2.633733</td>\n",
       "      <td>10.136103</td>\n",
       "      <td>10.892182</td>\n",
       "      <td>10.167938</td>\n",
       "      <td>11.853222</td>\n",
       "      <td>8.277645</td>\n",
       "      <td>8.966269</td>\n",
       "      <td>...</td>\n",
       "      <td>9.830270</td>\n",
       "      <td>12.700669</td>\n",
       "      <td>8.127033</td>\n",
       "      <td>4.583682</td>\n",
       "      <td>14.207693</td>\n",
       "      <td>11.124848</td>\n",
       "      <td>9.221416</td>\n",
       "      <td>6.063035</td>\n",
       "      <td>9.531294</td>\n",
       "      <td>11.578901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-C8-A1HE-01</th>\n",
       "      <td>7.399941</td>\n",
       "      <td>11.590931</td>\n",
       "      <td>9.617624</td>\n",
       "      <td>3.854843</td>\n",
       "      <td>9.238226</td>\n",
       "      <td>11.675139</td>\n",
       "      <td>12.240305</td>\n",
       "      <td>11.507753</td>\n",
       "      <td>9.101567</td>\n",
       "      <td>8.740199</td>\n",
       "      <td>...</td>\n",
       "      <td>9.910928</td>\n",
       "      <td>11.850661</td>\n",
       "      <td>8.174096</td>\n",
       "      <td>4.249703</td>\n",
       "      <td>14.427244</td>\n",
       "      <td>10.689840</td>\n",
       "      <td>9.324559</td>\n",
       "      <td>4.729313</td>\n",
       "      <td>9.938370</td>\n",
       "      <td>11.574674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A1-A0SQ-01</th>\n",
       "      <td>7.721054</td>\n",
       "      <td>9.337846</td>\n",
       "      <td>9.063252</td>\n",
       "      <td>3.938314</td>\n",
       "      <td>9.899231</td>\n",
       "      <td>10.615200</td>\n",
       "      <td>10.953656</td>\n",
       "      <td>11.271823</td>\n",
       "      <td>7.966302</td>\n",
       "      <td>7.418308</td>\n",
       "      <td>...</td>\n",
       "      <td>10.605893</td>\n",
       "      <td>11.888986</td>\n",
       "      <td>8.129179</td>\n",
       "      <td>3.975786</td>\n",
       "      <td>14.453963</td>\n",
       "      <td>11.377763</td>\n",
       "      <td>9.325198</td>\n",
       "      <td>4.182239</td>\n",
       "      <td>9.947186</td>\n",
       "      <td>11.632352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 DBF4|10926  DACH1|1602  BBS4|585  L3MBTL4|91133   TK1|7083  \\\n",
       "patient_id                                                                    \n",
       "TCGA-D8-A1XU-01    6.998086   10.125705  8.332896       4.537035   8.211207   \n",
       "TCGA-D8-A1XV-01    8.117341   11.005011  9.888690       7.498527   9.495441   \n",
       "TCGA-E9-A1N3-01    8.100588   13.055740  9.338570       2.633733  10.136103   \n",
       "TCGA-C8-A1HE-01    7.399941   11.590931  9.617624       3.854843   9.238226   \n",
       "TCGA-A1-A0SQ-01    7.721054    9.337846  9.063252       3.938314   9.899231   \n",
       "\n",
       "                 KIAA1370|56204  GPD1L|23171  RERG|85004  RAPGEF3|10411  \\\n",
       "patient_id                                                                \n",
       "TCGA-D8-A1XU-01       10.111945    10.140800   12.116795       8.603795   \n",
       "TCGA-D8-A1XV-01       12.370753    10.892996   11.942934       7.569660   \n",
       "TCGA-E9-A1N3-01       10.892182    10.167938   11.853222       8.277645   \n",
       "TCGA-C8-A1HE-01       11.675139    12.240305   11.507753       9.101567   \n",
       "TCGA-A1-A0SQ-01       10.615200    10.953656   11.271823       7.966302   \n",
       "\n",
       "                 FBXO36|130888  ...  ANO10|55129  FDFT1|2222  MED6|10001  \\\n",
       "patient_id                      ...                                        \n",
       "TCGA-D8-A1XU-01       8.009364  ...    10.645044   11.479985    7.971973   \n",
       "TCGA-D8-A1XV-01       8.433369  ...     9.554953   11.472607    8.678011   \n",
       "TCGA-E9-A1N3-01       8.966269  ...     9.830270   12.700669    8.127033   \n",
       "TCGA-C8-A1HE-01       8.740199  ...     9.910928   11.850661    8.174096   \n",
       "TCGA-A1-A0SQ-01       7.418308  ...    10.605893   11.888986    8.129179   \n",
       "\n",
       "                 INCA1|388324  MYH9|4627  MYH14|79784  BTBD10|84280  \\\n",
       "patient_id                                                            \n",
       "TCGA-D8-A1XU-01      4.004537  14.529590    11.192954      9.490083   \n",
       "TCGA-D8-A1XV-01      2.743644  13.900355    10.332066      9.084859   \n",
       "TCGA-E9-A1N3-01      4.583682  14.207693    11.124848      9.221416   \n",
       "TCGA-C8-A1HE-01      4.249703  14.427244    10.689840      9.324559   \n",
       "TCGA-A1-A0SQ-01      3.975786  14.453963    11.377763      9.325198   \n",
       "\n",
       "                 ACTR3C|653857  KIAA0146|23514  BSDC1|55108  \n",
       "patient_id                                                   \n",
       "TCGA-D8-A1XU-01       5.848237        9.455163    11.069669  \n",
       "TCGA-D8-A1XV-01       5.172484        9.365128    11.526008  \n",
       "TCGA-E9-A1N3-01       6.063035        9.531294    11.578901  \n",
       "TCGA-C8-A1HE-01       4.729313        9.938370    11.574674  \n",
       "TCGA-A1-A0SQ-01       4.182239        9.947186    11.632352  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrna_file = \"../R/TCGA BRCA/mrna_top1000.csv\"\n",
    "mrna_tcga = pd.read_csv(mrna_file, index_col=\"patient_id\")\n",
    "mrna_tcga.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10926</th>\n",
       "      <th>1602</th>\n",
       "      <th>585</th>\n",
       "      <th>91133</th>\n",
       "      <th>7083</th>\n",
       "      <th>56204</th>\n",
       "      <th>23171</th>\n",
       "      <th>85004</th>\n",
       "      <th>10411</th>\n",
       "      <th>130888</th>\n",
       "      <th>...</th>\n",
       "      <th>55129</th>\n",
       "      <th>2222</th>\n",
       "      <th>10001</th>\n",
       "      <th>388324</th>\n",
       "      <th>4627</th>\n",
       "      <th>79784</th>\n",
       "      <th>84280</th>\n",
       "      <th>653857</th>\n",
       "      <th>23514</th>\n",
       "      <th>55108</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-D8-A1XU-01</th>\n",
       "      <td>6.998086</td>\n",
       "      <td>10.125705</td>\n",
       "      <td>8.332896</td>\n",
       "      <td>4.537035</td>\n",
       "      <td>8.211207</td>\n",
       "      <td>10.111945</td>\n",
       "      <td>10.140800</td>\n",
       "      <td>12.116795</td>\n",
       "      <td>8.603795</td>\n",
       "      <td>8.009364</td>\n",
       "      <td>...</td>\n",
       "      <td>10.645044</td>\n",
       "      <td>11.479985</td>\n",
       "      <td>7.971973</td>\n",
       "      <td>4.004537</td>\n",
       "      <td>14.529590</td>\n",
       "      <td>11.192954</td>\n",
       "      <td>9.490083</td>\n",
       "      <td>5.848237</td>\n",
       "      <td>9.455163</td>\n",
       "      <td>11.069669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-D8-A1XV-01</th>\n",
       "      <td>8.117341</td>\n",
       "      <td>11.005011</td>\n",
       "      <td>9.888690</td>\n",
       "      <td>7.498527</td>\n",
       "      <td>9.495441</td>\n",
       "      <td>12.370753</td>\n",
       "      <td>10.892996</td>\n",
       "      <td>11.942934</td>\n",
       "      <td>7.569660</td>\n",
       "      <td>8.433369</td>\n",
       "      <td>...</td>\n",
       "      <td>9.554953</td>\n",
       "      <td>11.472607</td>\n",
       "      <td>8.678011</td>\n",
       "      <td>2.743644</td>\n",
       "      <td>13.900355</td>\n",
       "      <td>10.332066</td>\n",
       "      <td>9.084859</td>\n",
       "      <td>5.172484</td>\n",
       "      <td>9.365128</td>\n",
       "      <td>11.526008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-E9-A1N3-01</th>\n",
       "      <td>8.100588</td>\n",
       "      <td>13.055740</td>\n",
       "      <td>9.338570</td>\n",
       "      <td>2.633733</td>\n",
       "      <td>10.136103</td>\n",
       "      <td>10.892182</td>\n",
       "      <td>10.167938</td>\n",
       "      <td>11.853222</td>\n",
       "      <td>8.277645</td>\n",
       "      <td>8.966269</td>\n",
       "      <td>...</td>\n",
       "      <td>9.830270</td>\n",
       "      <td>12.700669</td>\n",
       "      <td>8.127033</td>\n",
       "      <td>4.583682</td>\n",
       "      <td>14.207693</td>\n",
       "      <td>11.124848</td>\n",
       "      <td>9.221416</td>\n",
       "      <td>6.063035</td>\n",
       "      <td>9.531294</td>\n",
       "      <td>11.578901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-C8-A1HE-01</th>\n",
       "      <td>7.399941</td>\n",
       "      <td>11.590931</td>\n",
       "      <td>9.617624</td>\n",
       "      <td>3.854843</td>\n",
       "      <td>9.238226</td>\n",
       "      <td>11.675139</td>\n",
       "      <td>12.240305</td>\n",
       "      <td>11.507753</td>\n",
       "      <td>9.101567</td>\n",
       "      <td>8.740199</td>\n",
       "      <td>...</td>\n",
       "      <td>9.910928</td>\n",
       "      <td>11.850661</td>\n",
       "      <td>8.174096</td>\n",
       "      <td>4.249703</td>\n",
       "      <td>14.427244</td>\n",
       "      <td>10.689840</td>\n",
       "      <td>9.324559</td>\n",
       "      <td>4.729313</td>\n",
       "      <td>9.938370</td>\n",
       "      <td>11.574674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A1-A0SQ-01</th>\n",
       "      <td>7.721054</td>\n",
       "      <td>9.337846</td>\n",
       "      <td>9.063252</td>\n",
       "      <td>3.938314</td>\n",
       "      <td>9.899231</td>\n",
       "      <td>10.615200</td>\n",
       "      <td>10.953656</td>\n",
       "      <td>11.271823</td>\n",
       "      <td>7.966302</td>\n",
       "      <td>7.418308</td>\n",
       "      <td>...</td>\n",
       "      <td>10.605893</td>\n",
       "      <td>11.888986</td>\n",
       "      <td>8.129179</td>\n",
       "      <td>3.975786</td>\n",
       "      <td>14.453963</td>\n",
       "      <td>11.377763</td>\n",
       "      <td>9.325198</td>\n",
       "      <td>4.182239</td>\n",
       "      <td>9.947186</td>\n",
       "      <td>11.632352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    10926       1602       585     91133       7083  \\\n",
       "patient_id                                                            \n",
       "TCGA-D8-A1XU-01  6.998086  10.125705  8.332896  4.537035   8.211207   \n",
       "TCGA-D8-A1XV-01  8.117341  11.005011  9.888690  7.498527   9.495441   \n",
       "TCGA-E9-A1N3-01  8.100588  13.055740  9.338570  2.633733  10.136103   \n",
       "TCGA-C8-A1HE-01  7.399941  11.590931  9.617624  3.854843   9.238226   \n",
       "TCGA-A1-A0SQ-01  7.721054   9.337846  9.063252  3.938314   9.899231   \n",
       "\n",
       "                     56204      23171      85004     10411    130888  ...  \\\n",
       "patient_id                                                            ...   \n",
       "TCGA-D8-A1XU-01  10.111945  10.140800  12.116795  8.603795  8.009364  ...   \n",
       "TCGA-D8-A1XV-01  12.370753  10.892996  11.942934  7.569660  8.433369  ...   \n",
       "TCGA-E9-A1N3-01  10.892182  10.167938  11.853222  8.277645  8.966269  ...   \n",
       "TCGA-C8-A1HE-01  11.675139  12.240305  11.507753  9.101567  8.740199  ...   \n",
       "TCGA-A1-A0SQ-01  10.615200  10.953656  11.271823  7.966302  7.418308  ...   \n",
       "\n",
       "                     55129       2222     10001    388324       4627  \\\n",
       "patient_id                                                             \n",
       "TCGA-D8-A1XU-01  10.645044  11.479985  7.971973  4.004537  14.529590   \n",
       "TCGA-D8-A1XV-01   9.554953  11.472607  8.678011  2.743644  13.900355   \n",
       "TCGA-E9-A1N3-01   9.830270  12.700669  8.127033  4.583682  14.207693   \n",
       "TCGA-C8-A1HE-01   9.910928  11.850661  8.174096  4.249703  14.427244   \n",
       "TCGA-A1-A0SQ-01  10.605893  11.888986  8.129179  3.975786  14.453963   \n",
       "\n",
       "                     79784     84280    653857     23514      55108  \n",
       "patient_id                                                           \n",
       "TCGA-D8-A1XU-01  11.192954  9.490083  5.848237  9.455163  11.069669  \n",
       "TCGA-D8-A1XV-01  10.332066  9.084859  5.172484  9.365128  11.526008  \n",
       "TCGA-E9-A1N3-01  11.124848  9.221416  6.063035  9.531294  11.578901  \n",
       "TCGA-C8-A1HE-01  10.689840  9.324559  4.729313  9.938370  11.574674  \n",
       "TCGA-A1-A0SQ-01  11.377763  9.325198  4.182239  9.947186  11.632352  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrna_tcga.columns = [x.split(\"|\")[1] for x in mrna_tcga.columns.tolist()]\n",
    "mrna_tcga.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10001</th>\n",
       "      <th>10011</th>\n",
       "      <th>100133941</th>\n",
       "      <th>100272147</th>\n",
       "      <th>10058</th>\n",
       "      <th>1009</th>\n",
       "      <th>10120</th>\n",
       "      <th>10147</th>\n",
       "      <th>10159</th>\n",
       "      <th>10168</th>\n",
       "      <th>...</th>\n",
       "      <th>9901</th>\n",
       "      <th>9911</th>\n",
       "      <th>9913</th>\n",
       "      <th>9918</th>\n",
       "      <th>9919</th>\n",
       "      <th>9920</th>\n",
       "      <th>9927</th>\n",
       "      <th>9945</th>\n",
       "      <th>9986</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MB-0002</th>\n",
       "      <td>0.509946</td>\n",
       "      <td>0.206836</td>\n",
       "      <td>0.631124</td>\n",
       "      <td>0.419623</td>\n",
       "      <td>0.283525</td>\n",
       "      <td>0.606140</td>\n",
       "      <td>0.597757</td>\n",
       "      <td>0.359288</td>\n",
       "      <td>0.620258</td>\n",
       "      <td>0.389117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399271</td>\n",
       "      <td>0.200939</td>\n",
       "      <td>0.376195</td>\n",
       "      <td>0.330310</td>\n",
       "      <td>0.485045</td>\n",
       "      <td>0.202522</td>\n",
       "      <td>0.351105</td>\n",
       "      <td>0.352889</td>\n",
       "      <td>0.467633</td>\n",
       "      <td>0.765941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0008</th>\n",
       "      <td>0.386395</td>\n",
       "      <td>0.488898</td>\n",
       "      <td>0.573119</td>\n",
       "      <td>0.438047</td>\n",
       "      <td>0.438743</td>\n",
       "      <td>0.359749</td>\n",
       "      <td>0.590322</td>\n",
       "      <td>0.313404</td>\n",
       "      <td>0.548219</td>\n",
       "      <td>0.502381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128685</td>\n",
       "      <td>0.092278</td>\n",
       "      <td>0.390609</td>\n",
       "      <td>0.312724</td>\n",
       "      <td>0.305650</td>\n",
       "      <td>0.122984</td>\n",
       "      <td>0.134333</td>\n",
       "      <td>0.199171</td>\n",
       "      <td>0.279175</td>\n",
       "      <td>0.694469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0010</th>\n",
       "      <td>0.454756</td>\n",
       "      <td>0.522068</td>\n",
       "      <td>0.460766</td>\n",
       "      <td>0.513480</td>\n",
       "      <td>0.290983</td>\n",
       "      <td>0.681901</td>\n",
       "      <td>0.395751</td>\n",
       "      <td>0.255849</td>\n",
       "      <td>0.621214</td>\n",
       "      <td>0.459585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380602</td>\n",
       "      <td>0.126612</td>\n",
       "      <td>0.550271</td>\n",
       "      <td>0.216863</td>\n",
       "      <td>0.620993</td>\n",
       "      <td>0.187716</td>\n",
       "      <td>0.151606</td>\n",
       "      <td>0.416084</td>\n",
       "      <td>0.330877</td>\n",
       "      <td>0.732725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0035</th>\n",
       "      <td>0.462371</td>\n",
       "      <td>0.407566</td>\n",
       "      <td>0.700211</td>\n",
       "      <td>0.364074</td>\n",
       "      <td>0.379525</td>\n",
       "      <td>0.110424</td>\n",
       "      <td>0.692389</td>\n",
       "      <td>0.445498</td>\n",
       "      <td>0.544630</td>\n",
       "      <td>0.640250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233189</td>\n",
       "      <td>0.052358</td>\n",
       "      <td>0.404973</td>\n",
       "      <td>0.268680</td>\n",
       "      <td>0.857693</td>\n",
       "      <td>0.323273</td>\n",
       "      <td>0.563302</td>\n",
       "      <td>0.025646</td>\n",
       "      <td>0.260921</td>\n",
       "      <td>0.306947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0036</th>\n",
       "      <td>0.401631</td>\n",
       "      <td>0.515361</td>\n",
       "      <td>0.571184</td>\n",
       "      <td>0.316034</td>\n",
       "      <td>0.366764</td>\n",
       "      <td>0.541313</td>\n",
       "      <td>0.601687</td>\n",
       "      <td>0.328046</td>\n",
       "      <td>0.670446</td>\n",
       "      <td>0.651387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369864</td>\n",
       "      <td>0.271615</td>\n",
       "      <td>0.409749</td>\n",
       "      <td>0.286881</td>\n",
       "      <td>0.498259</td>\n",
       "      <td>0.163885</td>\n",
       "      <td>0.544241</td>\n",
       "      <td>0.275509</td>\n",
       "      <td>0.243251</td>\n",
       "      <td>0.591624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  953 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               10001     10011  100133941  100272147     10058      1009  \\\n",
       "patient_id                                                                 \n",
       "MB-0002     0.509946  0.206836   0.631124   0.419623  0.283525  0.606140   \n",
       "MB-0008     0.386395  0.488898   0.573119   0.438047  0.438743  0.359749   \n",
       "MB-0010     0.454756  0.522068   0.460766   0.513480  0.290983  0.681901   \n",
       "MB-0035     0.462371  0.407566   0.700211   0.364074  0.379525  0.110424   \n",
       "MB-0036     0.401631  0.515361   0.571184   0.316034  0.366764  0.541313   \n",
       "\n",
       "               10120     10147     10159     10168  ...      9901      9911  \\\n",
       "patient_id                                          ...                       \n",
       "MB-0002     0.597757  0.359288  0.620258  0.389117  ...  0.399271  0.200939   \n",
       "MB-0008     0.590322  0.313404  0.548219  0.502381  ...  0.128685  0.092278   \n",
       "MB-0010     0.395751  0.255849  0.621214  0.459585  ...  0.380602  0.126612   \n",
       "MB-0035     0.692389  0.445498  0.544630  0.640250  ...  0.233189  0.052358   \n",
       "MB-0036     0.601687  0.328046  0.670446  0.651387  ...  0.369864  0.271615   \n",
       "\n",
       "                9913      9918      9919      9920      9927      9945  \\\n",
       "patient_id                                                               \n",
       "MB-0002     0.376195  0.330310  0.485045  0.202522  0.351105  0.352889   \n",
       "MB-0008     0.390609  0.312724  0.305650  0.122984  0.134333  0.199171   \n",
       "MB-0010     0.550271  0.216863  0.620993  0.187716  0.151606  0.416084   \n",
       "MB-0035     0.404973  0.268680  0.857693  0.323273  0.563302  0.025646   \n",
       "MB-0036     0.409749  0.286881  0.498259  0.163885  0.544241  0.275509   \n",
       "\n",
       "                9986       999  \n",
       "patient_id                      \n",
       "MB-0002     0.467633  0.765941  \n",
       "MB-0008     0.279175  0.694469  \n",
       "MB-0010     0.330877  0.732725  \n",
       "MB-0035     0.260921  0.306947  \n",
       "MB-0036     0.243251  0.591624  \n",
       "\n",
       "[5 rows x 953 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load metabric mrna and find if the column names match\n",
    "metabric_file = \"../R/METABRIC/metabric_mrna_common_genes.csv\"\n",
    "metabric = pd.read_csv(metabric_file, index_col=\"patient_id\")\n",
    "#Scaling data\n",
    "metabric = (metabric - metabric.min())/(metabric.max() - metabric.min())\n",
    "metabric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953\n"
     ]
    }
   ],
   "source": [
    "common = [x for x in metabric.columns.tolist() if x in mrna_tcga.columns.tolist()]\n",
    "print(len(common))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hsa-mir-576</th>\n",
       "      <th>hsa-mir-200b</th>\n",
       "      <th>hsa-mir-3687</th>\n",
       "      <th>hsa-mir-126</th>\n",
       "      <th>hsa-mir-26a-2</th>\n",
       "      <th>hsa-mir-101-1</th>\n",
       "      <th>hsa-mir-218-2</th>\n",
       "      <th>hsa-mir-223</th>\n",
       "      <th>hsa-mir-335</th>\n",
       "      <th>hsa-mir-1468</th>\n",
       "      <th>...</th>\n",
       "      <th>hsa-mir-217</th>\n",
       "      <th>hsa-mir-424</th>\n",
       "      <th>hsa-mir-581</th>\n",
       "      <th>hsa-mir-483</th>\n",
       "      <th>hsa-mir-3614</th>\n",
       "      <th>hsa-mir-16-1</th>\n",
       "      <th>hsa-mir-550a-2</th>\n",
       "      <th>hsa-mir-24-1</th>\n",
       "      <th>hsa-mir-508</th>\n",
       "      <th>hsa-mir-642a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-D8-A1XU-01</th>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.140952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270701</td>\n",
       "      <td>0.091211</td>\n",
       "      <td>0.095231</td>\n",
       "      <td>0.107789</td>\n",
       "      <td>0.076080</td>\n",
       "      <td>0.015915</td>\n",
       "      <td>0.027088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.078464</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>0.046753</td>\n",
       "      <td>0.256461</td>\n",
       "      <td>0.010449</td>\n",
       "      <td>0.070690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-D8-A1XV-01</th>\n",
       "      <td>0.073643</td>\n",
       "      <td>0.107791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097036</td>\n",
       "      <td>0.049377</td>\n",
       "      <td>0.077829</td>\n",
       "      <td>0.029053</td>\n",
       "      <td>0.020280</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.019187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.037773</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.032759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-E9-A1N3-01</th>\n",
       "      <td>0.071705</td>\n",
       "      <td>0.198585</td>\n",
       "      <td>0.017699</td>\n",
       "      <td>0.186619</td>\n",
       "      <td>0.057882</td>\n",
       "      <td>0.109587</td>\n",
       "      <td>0.067368</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.023702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.044661</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.063510</td>\n",
       "      <td>0.049351</td>\n",
       "      <td>0.093439</td>\n",
       "      <td>0.053473</td>\n",
       "      <td>0.110345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-C8-A1HE-01</th>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.107845</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.108195</td>\n",
       "      <td>0.049797</td>\n",
       "      <td>0.059035</td>\n",
       "      <td>0.072421</td>\n",
       "      <td>0.030105</td>\n",
       "      <td>0.016321</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.057869</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.041750</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.044828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A1-A0SQ-01</th>\n",
       "      <td>0.067829</td>\n",
       "      <td>0.039238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.028665</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.155172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hsa-mir-576  hsa-mir-200b  hsa-mir-3687  hsa-mir-126  \\\n",
       "patient_id                                                              \n",
       "TCGA-D8-A1XU-01     0.058140      0.140952      0.000000     0.270701   \n",
       "TCGA-D8-A1XV-01     0.073643      0.107791      0.000000     0.097036   \n",
       "TCGA-E9-A1N3-01     0.071705      0.198585      0.017699     0.186619   \n",
       "TCGA-C8-A1HE-01     0.046512      0.107845      0.008850     0.108195   \n",
       "TCGA-A1-A0SQ-01     0.067829      0.039238      0.000000     0.019845   \n",
       "\n",
       "                 hsa-mir-26a-2  hsa-mir-101-1  hsa-mir-218-2  hsa-mir-223  \\\n",
       "patient_id                                                                  \n",
       "TCGA-D8-A1XU-01       0.091211       0.095231       0.107789     0.076080   \n",
       "TCGA-D8-A1XV-01       0.049377       0.077829       0.029053     0.020280   \n",
       "TCGA-E9-A1N3-01       0.057882       0.109587       0.067368     0.039300   \n",
       "TCGA-C8-A1HE-01       0.049797       0.059035       0.072421     0.030105   \n",
       "TCGA-A1-A0SQ-01       0.008261       0.028665       0.007579     0.001512   \n",
       "\n",
       "                 hsa-mir-335  hsa-mir-1468  ...  hsa-mir-217  hsa-mir-424  \\\n",
       "patient_id                                  ...                             \n",
       "TCGA-D8-A1XU-01     0.015915      0.027088  ...     0.004411     0.078464   \n",
       "TCGA-D8-A1XV-01     0.010700      0.019187  ...     0.003170     0.012424   \n",
       "TCGA-E9-A1N3-01     0.021875      0.023702  ...     0.003446     0.044661   \n",
       "TCGA-C8-A1HE-01     0.016321      0.005643  ...     0.001792     0.057869   \n",
       "TCGA-A1-A0SQ-01     0.004267      0.004515  ...     0.001103     0.005261   \n",
       "\n",
       "                 hsa-mir-581  hsa-mir-483  hsa-mir-3614  hsa-mir-16-1  \\\n",
       "patient_id                                                              \n",
       "TCGA-D8-A1XU-01       0.3125     0.002911      0.001617      0.059937   \n",
       "TCGA-D8-A1XV-01       0.1250     0.000333      0.002426      0.082900   \n",
       "TCGA-E9-A1N3-01       0.6875     0.000832      0.002426      0.063510   \n",
       "TCGA-C8-A1HE-01       0.1250     0.001248      0.004448      0.066019   \n",
       "TCGA-A1-A0SQ-01       0.0625     0.000083      0.003235      0.010478   \n",
       "\n",
       "                 hsa-mir-550a-2  hsa-mir-24-1  hsa-mir-508  hsa-mir-642a  \n",
       "patient_id                                                                \n",
       "TCGA-D8-A1XU-01        0.046753      0.256461     0.010449      0.070690  \n",
       "TCGA-D8-A1XV-01        0.038961      0.037773     0.003380      0.032759  \n",
       "TCGA-E9-A1N3-01        0.049351      0.093439     0.053473      0.110345  \n",
       "TCGA-C8-A1HE-01        0.007792      0.041750     0.001537      0.044828  \n",
       "TCGA-A1-A0SQ-01        0.005195      0.009940     0.000615      0.155172  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meth_file = \"../R/TCGA BRCA/meth_top1000.csv\"\n",
    "mirna_file = \"../R/TCGA BRCA/mirna_anova.csv\"\n",
    "\n",
    "meth_tcga = pd.read_csv(meth_file, index_col=\"patient_id\")\n",
    "mirna_tcga = pd.read_csv(mirna_file, index_col=\"patient_id\")\n",
    "mirna_tcga.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10926</th>\n",
       "      <th>1602</th>\n",
       "      <th>585</th>\n",
       "      <th>91133</th>\n",
       "      <th>7083</th>\n",
       "      <th>56204</th>\n",
       "      <th>23171</th>\n",
       "      <th>85004</th>\n",
       "      <th>10411</th>\n",
       "      <th>130888</th>\n",
       "      <th>...</th>\n",
       "      <th>hsa-mir-217</th>\n",
       "      <th>hsa-mir-424</th>\n",
       "      <th>hsa-mir-581</th>\n",
       "      <th>hsa-mir-483</th>\n",
       "      <th>hsa-mir-3614</th>\n",
       "      <th>hsa-mir-16-1</th>\n",
       "      <th>hsa-mir-550a-2</th>\n",
       "      <th>hsa-mir-24-1</th>\n",
       "      <th>hsa-mir-508</th>\n",
       "      <th>hsa-mir-642a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA-D8-A1XU-01</th>\n",
       "      <td>0.277770</td>\n",
       "      <td>0.758159</td>\n",
       "      <td>0.378836</td>\n",
       "      <td>0.356571</td>\n",
       "      <td>0.434890</td>\n",
       "      <td>0.554010</td>\n",
       "      <td>0.492860</td>\n",
       "      <td>0.812734</td>\n",
       "      <td>0.599057</td>\n",
       "      <td>0.787462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.078464</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>0.046753</td>\n",
       "      <td>0.256461</td>\n",
       "      <td>0.010449</td>\n",
       "      <td>0.070690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-D8-A1XV-01</th>\n",
       "      <td>0.513189</td>\n",
       "      <td>0.830736</td>\n",
       "      <td>0.648579</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.566643</td>\n",
       "      <td>0.889481</td>\n",
       "      <td>0.607707</td>\n",
       "      <td>0.797190</td>\n",
       "      <td>0.454187</td>\n",
       "      <td>0.844195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.037773</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.032759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-E9-A1N3-01</th>\n",
       "      <td>0.509665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553200</td>\n",
       "      <td>0.152295</td>\n",
       "      <td>0.632370</td>\n",
       "      <td>0.669888</td>\n",
       "      <td>0.497003</td>\n",
       "      <td>0.789170</td>\n",
       "      <td>0.553367</td>\n",
       "      <td>0.915498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.044661</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.063510</td>\n",
       "      <td>0.049351</td>\n",
       "      <td>0.093439</td>\n",
       "      <td>0.053473</td>\n",
       "      <td>0.110345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-C8-A1HE-01</th>\n",
       "      <td>0.362294</td>\n",
       "      <td>0.879097</td>\n",
       "      <td>0.601582</td>\n",
       "      <td>0.283353</td>\n",
       "      <td>0.540255</td>\n",
       "      <td>0.786171</td>\n",
       "      <td>0.813419</td>\n",
       "      <td>0.758284</td>\n",
       "      <td>0.668789</td>\n",
       "      <td>0.885250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.057869</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.041750</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.044828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A1-A0SQ-01</th>\n",
       "      <td>0.429836</td>\n",
       "      <td>0.693130</td>\n",
       "      <td>0.505465</td>\n",
       "      <td>0.292312</td>\n",
       "      <td>0.608069</td>\n",
       "      <td>0.628752</td>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.737191</td>\n",
       "      <td>0.509752</td>\n",
       "      <td>0.708378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.155172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    10926      1602       585     91133      7083     56204  \\\n",
       "patient_id                                                                    \n",
       "TCGA-D8-A1XU-01  0.277770  0.758159  0.378836  0.356571  0.434890  0.554010   \n",
       "TCGA-D8-A1XV-01  0.513189  0.830736  0.648579  0.674419  0.566643  0.889481   \n",
       "TCGA-E9-A1N3-01  0.509665  1.000000  0.553200  0.152295  0.632370  0.669888   \n",
       "TCGA-C8-A1HE-01  0.362294  0.879097  0.601582  0.283353  0.540255  0.786171   \n",
       "TCGA-A1-A0SQ-01  0.429836  0.693130  0.505465  0.292312  0.608069  0.628752   \n",
       "\n",
       "                    23171     85004     10411    130888  ...  hsa-mir-217  \\\n",
       "patient_id                                               ...                \n",
       "TCGA-D8-A1XU-01  0.492860  0.812734  0.599057  0.787462  ...     0.004411   \n",
       "TCGA-D8-A1XV-01  0.607707  0.797190  0.454187  0.844195  ...     0.003170   \n",
       "TCGA-E9-A1N3-01  0.497003  0.789170  0.553367  0.915498  ...     0.003446   \n",
       "TCGA-C8-A1HE-01  0.813419  0.758284  0.668789  0.885250  ...     0.001792   \n",
       "TCGA-A1-A0SQ-01  0.616969  0.737191  0.509752  0.708378  ...     0.001103   \n",
       "\n",
       "                 hsa-mir-424  hsa-mir-581  hsa-mir-483  hsa-mir-3614  \\\n",
       "patient_id                                                             \n",
       "TCGA-D8-A1XU-01     0.078464       0.3125     0.002911      0.001617   \n",
       "TCGA-D8-A1XV-01     0.012424       0.1250     0.000333      0.002426   \n",
       "TCGA-E9-A1N3-01     0.044661       0.6875     0.000832      0.002426   \n",
       "TCGA-C8-A1HE-01     0.057869       0.1250     0.001248      0.004448   \n",
       "TCGA-A1-A0SQ-01     0.005261       0.0625     0.000083      0.003235   \n",
       "\n",
       "                 hsa-mir-16-1  hsa-mir-550a-2  hsa-mir-24-1  hsa-mir-508  \\\n",
       "patient_id                                                                 \n",
       "TCGA-D8-A1XU-01      0.059937        0.046753      0.256461     0.010449   \n",
       "TCGA-D8-A1XV-01      0.082900        0.038961      0.037773     0.003380   \n",
       "TCGA-E9-A1N3-01      0.063510        0.049351      0.093439     0.053473   \n",
       "TCGA-C8-A1HE-01      0.066019        0.007792      0.041750     0.001537   \n",
       "TCGA-A1-A0SQ-01      0.010478        0.005195      0.009940     0.000615   \n",
       "\n",
       "                 hsa-mir-642a  \n",
       "patient_id                     \n",
       "TCGA-D8-A1XU-01      0.070690  \n",
       "TCGA-D8-A1XV-01      0.032759  \n",
       "TCGA-E9-A1N3-01      0.110345  \n",
       "TCGA-C8-A1HE-01      0.044828  \n",
       "TCGA-A1-A0SQ-01      0.155172  \n",
       "\n",
       "[5 rows x 2257 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcga = pd.merge(pd.merge(mrna_tcga, meth_tcga, left_index=True, right_index=True), mirna_tcga,  left_index=True, right_index=True)\n",
    "datatypes = [\"mrna\"]*mrna_tcga.shape[1] + [\"meth\"]*meth_tcga.shape[1] + [\"mirna\"]*mirna_tcga.shape[1]\n",
    "\n",
    "tcga = (tcga - tcga.min())/(tcga.max() - tcga.min())\n",
    "tcga.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>10926</th>\n",
       "      <th>1602</th>\n",
       "      <th>585</th>\n",
       "      <th>91133</th>\n",
       "      <th>7083</th>\n",
       "      <th>56204</th>\n",
       "      <th>23171</th>\n",
       "      <th>85004</th>\n",
       "      <th>10411</th>\n",
       "      <th>130888</th>\n",
       "      <th>...</th>\n",
       "      <th>hsa-mir-217</th>\n",
       "      <th>hsa-mir-424</th>\n",
       "      <th>hsa-mir-581</th>\n",
       "      <th>hsa-mir-483</th>\n",
       "      <th>hsa-mir-3614</th>\n",
       "      <th>hsa-mir-16-1</th>\n",
       "      <th>hsa-mir-550a-2</th>\n",
       "      <th>hsa-mir-24-1</th>\n",
       "      <th>hsa-mir-508</th>\n",
       "      <th>hsa-mir-642a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">tcga</th>\n",
       "      <th>TCGA-D8-A1XU-01</th>\n",
       "      <td>0.277770</td>\n",
       "      <td>0.758159</td>\n",
       "      <td>0.378836</td>\n",
       "      <td>0.356571</td>\n",
       "      <td>0.434890</td>\n",
       "      <td>0.554010</td>\n",
       "      <td>0.492860</td>\n",
       "      <td>0.812734</td>\n",
       "      <td>0.599057</td>\n",
       "      <td>0.787462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.078464</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.059937</td>\n",
       "      <td>0.046753</td>\n",
       "      <td>0.256461</td>\n",
       "      <td>0.010449</td>\n",
       "      <td>0.070690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-D8-A1XV-01</th>\n",
       "      <td>0.513189</td>\n",
       "      <td>0.830736</td>\n",
       "      <td>0.648579</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0.566643</td>\n",
       "      <td>0.889481</td>\n",
       "      <td>0.607707</td>\n",
       "      <td>0.797190</td>\n",
       "      <td>0.454187</td>\n",
       "      <td>0.844195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.037773</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.032759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-E9-A1N3-01</th>\n",
       "      <td>0.509665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553200</td>\n",
       "      <td>0.152295</td>\n",
       "      <td>0.632370</td>\n",
       "      <td>0.669888</td>\n",
       "      <td>0.497003</td>\n",
       "      <td>0.789170</td>\n",
       "      <td>0.553367</td>\n",
       "      <td>0.915498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.044661</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.000832</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.063510</td>\n",
       "      <td>0.049351</td>\n",
       "      <td>0.093439</td>\n",
       "      <td>0.053473</td>\n",
       "      <td>0.110345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-C8-A1HE-01</th>\n",
       "      <td>0.362294</td>\n",
       "      <td>0.879097</td>\n",
       "      <td>0.601582</td>\n",
       "      <td>0.283353</td>\n",
       "      <td>0.540255</td>\n",
       "      <td>0.786171</td>\n",
       "      <td>0.813419</td>\n",
       "      <td>0.758284</td>\n",
       "      <td>0.668789</td>\n",
       "      <td>0.885250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.057869</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.041750</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.044828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA-A1-A0SQ-01</th>\n",
       "      <td>0.429836</td>\n",
       "      <td>0.693130</td>\n",
       "      <td>0.505465</td>\n",
       "      <td>0.292312</td>\n",
       "      <td>0.608069</td>\n",
       "      <td>0.628752</td>\n",
       "      <td>0.616969</td>\n",
       "      <td>0.737191</td>\n",
       "      <td>0.509752</td>\n",
       "      <td>0.708378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.010478</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.155172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">metabric</th>\n",
       "      <th>MB-7295</th>\n",
       "      <td>0.512974</td>\n",
       "      <td>0.088283</td>\n",
       "      <td>0.375981</td>\n",
       "      <td>0.184202</td>\n",
       "      <td>0.354885</td>\n",
       "      <td>0.523634</td>\n",
       "      <td>0.540736</td>\n",
       "      <td>0.403586</td>\n",
       "      <td>0.129892</td>\n",
       "      <td>0.558842</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-7296</th>\n",
       "      <td>0.264436</td>\n",
       "      <td>0.346990</td>\n",
       "      <td>0.316426</td>\n",
       "      <td>0.358322</td>\n",
       "      <td>0.532548</td>\n",
       "      <td>0.515167</td>\n",
       "      <td>0.210094</td>\n",
       "      <td>0.496851</td>\n",
       "      <td>0.279874</td>\n",
       "      <td>0.197045</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-7297</th>\n",
       "      <td>0.440437</td>\n",
       "      <td>0.264770</td>\n",
       "      <td>0.339046</td>\n",
       "      <td>0.248301</td>\n",
       "      <td>0.489982</td>\n",
       "      <td>0.416565</td>\n",
       "      <td>0.566007</td>\n",
       "      <td>0.601470</td>\n",
       "      <td>0.116188</td>\n",
       "      <td>0.532407</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-7298</th>\n",
       "      <td>0.438382</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>0.398268</td>\n",
       "      <td>0.294536</td>\n",
       "      <td>0.400486</td>\n",
       "      <td>0.423778</td>\n",
       "      <td>0.564141</td>\n",
       "      <td>0.474119</td>\n",
       "      <td>0.203041</td>\n",
       "      <td>0.651086</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-7299</th>\n",
       "      <td>0.475670</td>\n",
       "      <td>0.334992</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>0.234683</td>\n",
       "      <td>0.482957</td>\n",
       "      <td>0.294879</td>\n",
       "      <td>0.348325</td>\n",
       "      <td>0.426073</td>\n",
       "      <td>0.140683</td>\n",
       "      <td>0.312985</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2614 rows  2257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             10926      1602       585     91133      7083  \\\n",
       "         patient_id                                                          \n",
       "tcga     TCGA-D8-A1XU-01  0.277770  0.758159  0.378836  0.356571  0.434890   \n",
       "         TCGA-D8-A1XV-01  0.513189  0.830736  0.648579  0.674419  0.566643   \n",
       "         TCGA-E9-A1N3-01  0.509665  1.000000  0.553200  0.152295  0.632370   \n",
       "         TCGA-C8-A1HE-01  0.362294  0.879097  0.601582  0.283353  0.540255   \n",
       "         TCGA-A1-A0SQ-01  0.429836  0.693130  0.505465  0.292312  0.608069   \n",
       "...                            ...       ...       ...       ...       ...   \n",
       "metabric MB-7295          0.512974  0.088283  0.375981  0.184202  0.354885   \n",
       "         MB-7296          0.264436  0.346990  0.316426  0.358322  0.532548   \n",
       "         MB-7297          0.440437  0.264770  0.339046  0.248301  0.489982   \n",
       "         MB-7298          0.438382  0.044880  0.398268  0.294536  0.400486   \n",
       "         MB-7299          0.475670  0.334992  0.300371  0.234683  0.482957   \n",
       "\n",
       "                             56204     23171     85004     10411    130888  \\\n",
       "         patient_id                                                          \n",
       "tcga     TCGA-D8-A1XU-01  0.554010  0.492860  0.812734  0.599057  0.787462   \n",
       "         TCGA-D8-A1XV-01  0.889481  0.607707  0.797190  0.454187  0.844195   \n",
       "         TCGA-E9-A1N3-01  0.669888  0.497003  0.789170  0.553367  0.915498   \n",
       "         TCGA-C8-A1HE-01  0.786171  0.813419  0.758284  0.668789  0.885250   \n",
       "         TCGA-A1-A0SQ-01  0.628752  0.616969  0.737191  0.509752  0.708378   \n",
       "...                            ...       ...       ...       ...       ...   \n",
       "metabric MB-7295          0.523634  0.540736  0.403586  0.129892  0.558842   \n",
       "         MB-7296          0.515167  0.210094  0.496851  0.279874  0.197045   \n",
       "         MB-7297          0.416565  0.566007  0.601470  0.116188  0.532407   \n",
       "         MB-7298          0.423778  0.564141  0.474119  0.203041  0.651086   \n",
       "         MB-7299          0.294879  0.348325  0.426073  0.140683  0.312985   \n",
       "\n",
       "                          ...  hsa-mir-217  hsa-mir-424  hsa-mir-581  \\\n",
       "         patient_id       ...                                          \n",
       "tcga     TCGA-D8-A1XU-01  ...     0.004411     0.078464       0.3125   \n",
       "         TCGA-D8-A1XV-01  ...     0.003170     0.012424       0.1250   \n",
       "         TCGA-E9-A1N3-01  ...     0.003446     0.044661       0.6875   \n",
       "         TCGA-C8-A1HE-01  ...     0.001792     0.057869       0.1250   \n",
       "         TCGA-A1-A0SQ-01  ...     0.001103     0.005261       0.0625   \n",
       "...                       ...          ...          ...          ...   \n",
       "metabric MB-7295          ...          NaN          NaN          NaN   \n",
       "         MB-7296          ...          NaN          NaN          NaN   \n",
       "         MB-7297          ...          NaN          NaN          NaN   \n",
       "         MB-7298          ...          NaN          NaN          NaN   \n",
       "         MB-7299          ...          NaN          NaN          NaN   \n",
       "\n",
       "                          hsa-mir-483  hsa-mir-3614  hsa-mir-16-1  \\\n",
       "         patient_id                                                 \n",
       "tcga     TCGA-D8-A1XU-01     0.002911      0.001617      0.059937   \n",
       "         TCGA-D8-A1XV-01     0.000333      0.002426      0.082900   \n",
       "         TCGA-E9-A1N3-01     0.000832      0.002426      0.063510   \n",
       "         TCGA-C8-A1HE-01     0.001248      0.004448      0.066019   \n",
       "         TCGA-A1-A0SQ-01     0.000083      0.003235      0.010478   \n",
       "...                               ...           ...           ...   \n",
       "metabric MB-7295                  NaN           NaN           NaN   \n",
       "         MB-7296                  NaN           NaN           NaN   \n",
       "         MB-7297                  NaN           NaN           NaN   \n",
       "         MB-7298                  NaN           NaN           NaN   \n",
       "         MB-7299                  NaN           NaN           NaN   \n",
       "\n",
       "                          hsa-mir-550a-2  hsa-mir-24-1  hsa-mir-508  \\\n",
       "         patient_id                                                   \n",
       "tcga     TCGA-D8-A1XU-01        0.046753      0.256461     0.010449   \n",
       "         TCGA-D8-A1XV-01        0.038961      0.037773     0.003380   \n",
       "         TCGA-E9-A1N3-01        0.049351      0.093439     0.053473   \n",
       "         TCGA-C8-A1HE-01        0.007792      0.041750     0.001537   \n",
       "         TCGA-A1-A0SQ-01        0.005195      0.009940     0.000615   \n",
       "...                                  ...           ...          ...   \n",
       "metabric MB-7295                     NaN           NaN          NaN   \n",
       "         MB-7296                     NaN           NaN          NaN   \n",
       "         MB-7297                     NaN           NaN          NaN   \n",
       "         MB-7298                     NaN           NaN          NaN   \n",
       "         MB-7299                     NaN           NaN          NaN   \n",
       "\n",
       "                          hsa-mir-642a  \n",
       "         patient_id                     \n",
       "tcga     TCGA-D8-A1XU-01      0.070690  \n",
       "         TCGA-D8-A1XV-01      0.032759  \n",
       "         TCGA-E9-A1N3-01      0.110345  \n",
       "         TCGA-C8-A1HE-01      0.044828  \n",
       "         TCGA-A1-A0SQ-01      0.155172  \n",
       "...                                ...  \n",
       "metabric MB-7295                   NaN  \n",
       "         MB-7296                   NaN  \n",
       "         MB-7297                   NaN  \n",
       "         MB-7298                   NaN  \n",
       "         MB-7299                   NaN  \n",
       "\n",
       "[2614 rows x 2257 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.concat([tcga, metabric], keys=[\"tcga\", \"metabric\"])\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10926</th>\n",
       "      <th>1602</th>\n",
       "      <th>585</th>\n",
       "      <th>91133</th>\n",
       "      <th>7083</th>\n",
       "      <th>56204</th>\n",
       "      <th>23171</th>\n",
       "      <th>85004</th>\n",
       "      <th>10411</th>\n",
       "      <th>130888</th>\n",
       "      <th>...</th>\n",
       "      <th>hsa-mir-217</th>\n",
       "      <th>hsa-mir-424</th>\n",
       "      <th>hsa-mir-581</th>\n",
       "      <th>hsa-mir-483</th>\n",
       "      <th>hsa-mir-3614</th>\n",
       "      <th>hsa-mir-16-1</th>\n",
       "      <th>hsa-mir-550a-2</th>\n",
       "      <th>hsa-mir-24-1</th>\n",
       "      <th>hsa-mir-508</th>\n",
       "      <th>hsa-mir-642a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MB-0002</th>\n",
       "      <td>0.437020</td>\n",
       "      <td>0.385384</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.311753</td>\n",
       "      <td>0.245052</td>\n",
       "      <td>0.478552</td>\n",
       "      <td>0.801680</td>\n",
       "      <td>0.587668</td>\n",
       "      <td>0.068507</td>\n",
       "      <td>0.534533</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0008</th>\n",
       "      <td>0.397687</td>\n",
       "      <td>0.167070</td>\n",
       "      <td>0.339732</td>\n",
       "      <td>0.329731</td>\n",
       "      <td>0.449393</td>\n",
       "      <td>0.471928</td>\n",
       "      <td>0.484342</td>\n",
       "      <td>0.348926</td>\n",
       "      <td>0.180066</td>\n",
       "      <td>0.180992</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0010</th>\n",
       "      <td>0.564101</td>\n",
       "      <td>0.384719</td>\n",
       "      <td>0.331412</td>\n",
       "      <td>0.379296</td>\n",
       "      <td>0.551627</td>\n",
       "      <td>0.316974</td>\n",
       "      <td>0.632291</td>\n",
       "      <td>0.353556</td>\n",
       "      <td>0.116122</td>\n",
       "      <td>0.554031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0035</th>\n",
       "      <td>0.666748</td>\n",
       "      <td>0.716947</td>\n",
       "      <td>0.275349</td>\n",
       "      <td>0.277973</td>\n",
       "      <td>0.461391</td>\n",
       "      <td>0.583006</td>\n",
       "      <td>0.872315</td>\n",
       "      <td>0.370317</td>\n",
       "      <td>0.101373</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0036</th>\n",
       "      <td>0.537628</td>\n",
       "      <td>0.731964</td>\n",
       "      <td>0.575322</td>\n",
       "      <td>0.301746</td>\n",
       "      <td>0.365444</td>\n",
       "      <td>0.429494</td>\n",
       "      <td>0.471616</td>\n",
       "      <td>0.554430</td>\n",
       "      <td>0.143824</td>\n",
       "      <td>0.511059</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-7295</th>\n",
       "      <td>0.512974</td>\n",
       "      <td>0.088283</td>\n",
       "      <td>0.375981</td>\n",
       "      <td>0.184202</td>\n",
       "      <td>0.354885</td>\n",
       "      <td>0.523634</td>\n",
       "      <td>0.540736</td>\n",
       "      <td>0.403586</td>\n",
       "      <td>0.129892</td>\n",
       "      <td>0.558842</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-7296</th>\n",
       "      <td>0.264436</td>\n",
       "      <td>0.346990</td>\n",
       "      <td>0.316426</td>\n",
       "      <td>0.358322</td>\n",
       "      <td>0.532548</td>\n",
       "      <td>0.515167</td>\n",
       "      <td>0.210094</td>\n",
       "      <td>0.496851</td>\n",
       "      <td>0.279874</td>\n",
       "      <td>0.197045</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-7297</th>\n",
       "      <td>0.440437</td>\n",
       "      <td>0.264770</td>\n",
       "      <td>0.339046</td>\n",
       "      <td>0.248301</td>\n",
       "      <td>0.489982</td>\n",
       "      <td>0.416565</td>\n",
       "      <td>0.566007</td>\n",
       "      <td>0.601470</td>\n",
       "      <td>0.116188</td>\n",
       "      <td>0.532407</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-7298</th>\n",
       "      <td>0.438382</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>0.398268</td>\n",
       "      <td>0.294536</td>\n",
       "      <td>0.400486</td>\n",
       "      <td>0.423778</td>\n",
       "      <td>0.564141</td>\n",
       "      <td>0.474119</td>\n",
       "      <td>0.203041</td>\n",
       "      <td>0.651086</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-7299</th>\n",
       "      <td>0.475670</td>\n",
       "      <td>0.334992</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>0.234683</td>\n",
       "      <td>0.482957</td>\n",
       "      <td>0.294879</td>\n",
       "      <td>0.348325</td>\n",
       "      <td>0.426073</td>\n",
       "      <td>0.140683</td>\n",
       "      <td>0.312985</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1992 rows  2257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               10926      1602       585     91133      7083     56204  \\\n",
       "patient_id                                                               \n",
       "MB-0002     0.437020  0.385384  0.453125  0.311753  0.245052  0.478552   \n",
       "MB-0008     0.397687  0.167070  0.339732  0.329731  0.449393  0.471928   \n",
       "MB-0010     0.564101  0.384719  0.331412  0.379296  0.551627  0.316974   \n",
       "MB-0035     0.666748  0.716947  0.275349  0.277973  0.461391  0.583006   \n",
       "MB-0036     0.537628  0.731964  0.575322  0.301746  0.365444  0.429494   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "MB-7295     0.512974  0.088283  0.375981  0.184202  0.354885  0.523634   \n",
       "MB-7296     0.264436  0.346990  0.316426  0.358322  0.532548  0.515167   \n",
       "MB-7297     0.440437  0.264770  0.339046  0.248301  0.489982  0.416565   \n",
       "MB-7298     0.438382  0.044880  0.398268  0.294536  0.400486  0.423778   \n",
       "MB-7299     0.475670  0.334992  0.300371  0.234683  0.482957  0.294879   \n",
       "\n",
       "               23171     85004     10411    130888  ...  hsa-mir-217  \\\n",
       "patient_id                                          ...                \n",
       "MB-0002     0.801680  0.587668  0.068507  0.534533  ...          NaN   \n",
       "MB-0008     0.484342  0.348926  0.180066  0.180992  ...          NaN   \n",
       "MB-0010     0.632291  0.353556  0.116122  0.554031  ...          NaN   \n",
       "MB-0035     0.872315  0.370317  0.101373  0.294118  ...          NaN   \n",
       "MB-0036     0.471616  0.554430  0.143824  0.511059  ...          NaN   \n",
       "...              ...       ...       ...       ...  ...          ...   \n",
       "MB-7295     0.540736  0.403586  0.129892  0.558842  ...          NaN   \n",
       "MB-7296     0.210094  0.496851  0.279874  0.197045  ...          NaN   \n",
       "MB-7297     0.566007  0.601470  0.116188  0.532407  ...          NaN   \n",
       "MB-7298     0.564141  0.474119  0.203041  0.651086  ...          NaN   \n",
       "MB-7299     0.348325  0.426073  0.140683  0.312985  ...          NaN   \n",
       "\n",
       "            hsa-mir-424  hsa-mir-581  hsa-mir-483  hsa-mir-3614  hsa-mir-16-1  \\\n",
       "patient_id                                                                      \n",
       "MB-0002             NaN          NaN          NaN           NaN           NaN   \n",
       "MB-0008             NaN          NaN          NaN           NaN           NaN   \n",
       "MB-0010             NaN          NaN          NaN           NaN           NaN   \n",
       "MB-0035             NaN          NaN          NaN           NaN           NaN   \n",
       "MB-0036             NaN          NaN          NaN           NaN           NaN   \n",
       "...                 ...          ...          ...           ...           ...   \n",
       "MB-7295             NaN          NaN          NaN           NaN           NaN   \n",
       "MB-7296             NaN          NaN          NaN           NaN           NaN   \n",
       "MB-7297             NaN          NaN          NaN           NaN           NaN   \n",
       "MB-7298             NaN          NaN          NaN           NaN           NaN   \n",
       "MB-7299             NaN          NaN          NaN           NaN           NaN   \n",
       "\n",
       "            hsa-mir-550a-2  hsa-mir-24-1  hsa-mir-508  hsa-mir-642a  \n",
       "patient_id                                                           \n",
       "MB-0002                NaN           NaN          NaN           NaN  \n",
       "MB-0008                NaN           NaN          NaN           NaN  \n",
       "MB-0010                NaN           NaN          NaN           NaN  \n",
       "MB-0035                NaN           NaN          NaN           NaN  \n",
       "MB-0036                NaN           NaN          NaN           NaN  \n",
       "...                    ...           ...          ...           ...  \n",
       "MB-7295                NaN           NaN          NaN           NaN  \n",
       "MB-7296                NaN           NaN          NaN           NaN  \n",
       "MB-7297                NaN           NaN          NaN           NaN  \n",
       "MB-7298                NaN           NaN          NaN           NaN  \n",
       "MB-7299                NaN           NaN          NaN           NaN  \n",
       "\n",
       "[1992 rows x 2257 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.loc[\"metabric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10926</th>\n",
       "      <th>1602</th>\n",
       "      <th>585</th>\n",
       "      <th>91133</th>\n",
       "      <th>7083</th>\n",
       "      <th>56204</th>\n",
       "      <th>23171</th>\n",
       "      <th>85004</th>\n",
       "      <th>10411</th>\n",
       "      <th>130888</th>\n",
       "      <th>...</th>\n",
       "      <th>hsa-mir-217</th>\n",
       "      <th>hsa-mir-424</th>\n",
       "      <th>hsa-mir-581</th>\n",
       "      <th>hsa-mir-483</th>\n",
       "      <th>hsa-mir-3614</th>\n",
       "      <th>hsa-mir-16-1</th>\n",
       "      <th>hsa-mir-550a-2</th>\n",
       "      <th>hsa-mir-24-1</th>\n",
       "      <th>hsa-mir-508</th>\n",
       "      <th>hsa-mir-642a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MB-0002</th>\n",
       "      <td>0.437020</td>\n",
       "      <td>0.385384</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.311753</td>\n",
       "      <td>0.245052</td>\n",
       "      <td>0.478552</td>\n",
       "      <td>0.801680</td>\n",
       "      <td>0.587668</td>\n",
       "      <td>0.068507</td>\n",
       "      <td>0.534533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025354</td>\n",
       "      <td>0.073432</td>\n",
       "      <td>0.15500</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>0.039986</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.140517</td>\n",
       "      <td>0.013602</td>\n",
       "      <td>0.036931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0008</th>\n",
       "      <td>0.397687</td>\n",
       "      <td>0.167070</td>\n",
       "      <td>0.339732</td>\n",
       "      <td>0.329731</td>\n",
       "      <td>0.449393</td>\n",
       "      <td>0.471928</td>\n",
       "      <td>0.484342</td>\n",
       "      <td>0.348926</td>\n",
       "      <td>0.180066</td>\n",
       "      <td>0.180992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028119</td>\n",
       "      <td>0.070049</td>\n",
       "      <td>0.11750</td>\n",
       "      <td>0.001668</td>\n",
       "      <td>0.030724</td>\n",
       "      <td>0.036758</td>\n",
       "      <td>0.024519</td>\n",
       "      <td>0.116660</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.028276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0010</th>\n",
       "      <td>0.564101</td>\n",
       "      <td>0.384719</td>\n",
       "      <td>0.331412</td>\n",
       "      <td>0.379296</td>\n",
       "      <td>0.551627</td>\n",
       "      <td>0.316974</td>\n",
       "      <td>0.632291</td>\n",
       "      <td>0.353556</td>\n",
       "      <td>0.116122</td>\n",
       "      <td>0.554031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024179</td>\n",
       "      <td>0.080385</td>\n",
       "      <td>0.18125</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.044510</td>\n",
       "      <td>0.027584</td>\n",
       "      <td>0.171292</td>\n",
       "      <td>0.010061</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0035</th>\n",
       "      <td>0.666748</td>\n",
       "      <td>0.716947</td>\n",
       "      <td>0.275349</td>\n",
       "      <td>0.277973</td>\n",
       "      <td>0.461391</td>\n",
       "      <td>0.583006</td>\n",
       "      <td>0.872315</td>\n",
       "      <td>0.370317</td>\n",
       "      <td>0.101373</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025264</td>\n",
       "      <td>0.067114</td>\n",
       "      <td>0.15750</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.038491</td>\n",
       "      <td>0.021974</td>\n",
       "      <td>0.090775</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>0.043448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MB-0036</th>\n",
       "      <td>0.537628</td>\n",
       "      <td>0.731964</td>\n",
       "      <td>0.575322</td>\n",
       "      <td>0.301746</td>\n",
       "      <td>0.365444</td>\n",
       "      <td>0.429494</td>\n",
       "      <td>0.471616</td>\n",
       "      <td>0.554430</td>\n",
       "      <td>0.143824</td>\n",
       "      <td>0.511059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>0.062037</td>\n",
       "      <td>0.14125</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.040601</td>\n",
       "      <td>0.022234</td>\n",
       "      <td>0.100119</td>\n",
       "      <td>0.012526</td>\n",
       "      <td>0.039172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  2257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               10926      1602       585     91133      7083     56204  \\\n",
       "patient_id                                                               \n",
       "MB-0002     0.437020  0.385384  0.453125  0.311753  0.245052  0.478552   \n",
       "MB-0008     0.397687  0.167070  0.339732  0.329731  0.449393  0.471928   \n",
       "MB-0010     0.564101  0.384719  0.331412  0.379296  0.551627  0.316974   \n",
       "MB-0035     0.666748  0.716947  0.275349  0.277973  0.461391  0.583006   \n",
       "MB-0036     0.537628  0.731964  0.575322  0.301746  0.365444  0.429494   \n",
       "\n",
       "               23171     85004     10411    130888  ...  hsa-mir-217  \\\n",
       "patient_id                                          ...                \n",
       "MB-0002     0.801680  0.587668  0.068507  0.534533  ...     0.025354   \n",
       "MB-0008     0.484342  0.348926  0.180066  0.180992  ...     0.028119   \n",
       "MB-0010     0.632291  0.353556  0.116122  0.554031  ...     0.024179   \n",
       "MB-0035     0.872315  0.370317  0.101373  0.294118  ...     0.025264   \n",
       "MB-0036     0.471616  0.554430  0.143824  0.511059  ...     0.005829   \n",
       "\n",
       "            hsa-mir-424  hsa-mir-581  hsa-mir-483  hsa-mir-3614  hsa-mir-16-1  \\\n",
       "patient_id                                                                      \n",
       "MB-0002        0.073432      0.15500     0.002194      0.006777      0.039986   \n",
       "MB-0008        0.070049      0.11750     0.001668      0.030724      0.036758   \n",
       "MB-0010        0.080385      0.18125     0.002166      0.027279      0.044510   \n",
       "MB-0035        0.067114      0.15750     0.002738      0.007740      0.038491   \n",
       "MB-0036        0.062037      0.14125     0.002770      0.005839      0.040601   \n",
       "\n",
       "            hsa-mir-550a-2  hsa-mir-24-1  hsa-mir-508  hsa-mir-642a  \n",
       "patient_id                                                           \n",
       "MB-0002           0.024104      0.140517     0.013602      0.036931  \n",
       "MB-0008           0.024519      0.116660     0.011008      0.028276  \n",
       "MB-0010           0.027584      0.171292     0.010061      0.045000  \n",
       "MB-0035           0.021974      0.090775     0.006079      0.043448  \n",
       "MB-0036           0.022234      0.100119     0.012526      0.039172  \n",
       "\n",
       "[5 rows x 2257 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=50)\n",
    "imputer.fit(merged_data.loc[\"tcga\"])\n",
    "\n",
    "metabric_imputed = imputer.transform(merged_data.loc[\"metabric\"])\n",
    "metabric_imputed = pd.DataFrame(metabric_imputed, columns = merged_data.columns, index = merged_data.loc[\"metabric\"].index)\n",
    "metabric_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, divide the data frames up according to the list \"datatypes\" and then save them to individual csv files in the R/METABRIC folder and then supply them to the model to work on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
